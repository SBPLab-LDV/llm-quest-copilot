#!/usr/bin/env python3
"""
çµ±ä¸€ DSPy å°è©±æ¨¡çµ„

å°‡åŸæœ¬çš„å¤šæ­¥é©Ÿèª¿ç”¨ï¼ˆæƒ…å¢ƒåˆ†é¡ã€å›æ‡‰ç”Ÿæˆã€ç‹€æ…‹è½‰æ›ï¼‰åˆä½µç‚ºå–®ä¸€ API èª¿ç”¨ï¼Œ
ä»¥è§£æ±º API é…é¡é™åˆ¶å•é¡Œã€‚
"""

import dspy
import json
import logging
from typing import List, Dict, Any, Optional, Union
from datetime import datetime

from .dialogue_module import DSPyDialogueModule
from .signatures import PatientResponseSignature

logger = logging.getLogger(__name__)


class UnifiedPatientResponseSignature(dspy.Signature):
    """çµ±ä¸€çš„ç—…æ‚£å›æ‡‰ç”Ÿæˆç°½å - æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†ç‰ˆæœ¬
    
    å°‡æƒ…å¢ƒåˆ†é¡ã€å›æ‡‰ç”Ÿæˆã€ç‹€æ…‹åˆ¤æ–·åˆä½µç‚ºå–®ä¸€èª¿ç”¨ï¼Œ
    æ¸›å°‘ API ä½¿ç”¨æ¬¡æ•¸å¾ 3æ¬¡ é™ä½åˆ° 1æ¬¡ã€‚
    
    æ ¸å¿ƒåŸå‰‡ï¼š
    1. ä»¥å·²å»ºç«‹çš„ç—…æ‚£è§’è‰²è‡ªç„¶å›æ‡‰
    2. é¿å…ä¸å¿…è¦çš„è‡ªæˆ‘ä»‹ç´¹
    3. ä¿æŒè§’è‰²ä¸€è‡´æ€§å’Œå°è©±æµæš¢åº¦
    """
    
    # è¼¸å…¥æ¬„ä½ - è­·ç†äººå“¡å’Œå°è©±ç›¸é—œä¿¡æ¯
    user_input = dspy.InputField(desc="è­·ç†äººå“¡çš„è¼¸å…¥æˆ–å•é¡Œ")
    character_name = dspy.InputField(desc="ç—…æ‚£è§’è‰²çš„åç¨±")
    character_persona = dspy.InputField(desc="ç—…æ‚£çš„å€‹æ€§æè¿°")
    character_backstory = dspy.InputField(desc="ç—…æ‚£çš„èƒŒæ™¯æ•…äº‹")
    character_goal = dspy.InputField(desc="ç—…æ‚£çš„ç›®æ¨™")
    character_details = dspy.InputField(desc="ç—…æ‚£çš„è©³ç´°è¨­å®šï¼ŒåŒ…å«å›ºå®šå’Œæµ®å‹•è¨­å®šçš„YAMLæ ¼å¼å­—ç¬¦ä¸²")
    conversation_history = dspy.InputField(desc="æœ€è¿‘çš„å°è©±æ­·å²ï¼Œä»¥æ›è¡Œåˆ†éš”ï¼ŒåŒ…å«è§’è‰²ä¸€è‡´æ€§æé†’")
    available_contexts = dspy.InputField(desc="å¯ç”¨çš„å°è©±æƒ…å¢ƒåˆ—è¡¨")
    
    # è¼¸å‡ºæ¬„ä½ - çµ±ä¸€çš„å›æ‡‰çµæœ  
    reasoning = dspy.OutputField(desc="æ¨ç†éç¨‹ï¼šåŒ…å«æƒ…å¢ƒåˆ†æã€è§’è‰²ä¸€è‡´æ€§æª¢æŸ¥ã€å›æ‡‰æ€è€ƒå’Œç‹€æ…‹è©•ä¼°ã€‚å¿…é ˆç¢ºèªä¸æœƒé€²è¡Œè‡ªæˆ‘ä»‹ç´¹ã€‚")
    character_consistency_check = dspy.OutputField(desc="è§’è‰²ä¸€è‡´æ€§æª¢æŸ¥ï¼šç¢ºèªå›æ‡‰ç¬¦åˆå·²å»ºç«‹çš„è§’è‰²äººæ ¼ï¼Œä¸åŒ…å«è‡ªæˆ‘ä»‹ç´¹ã€‚å›ç­” YES æˆ– NO")
    context_classification = dspy.OutputField(desc="å°è©±æƒ…å¢ƒåˆ†é¡ï¼švital_signs_examples, daily_routine_examples, treatment_examples ç­‰")
    confidence = dspy.OutputField(desc="æƒ…å¢ƒåˆ†é¡çš„ä¿¡å¿ƒåº¦ï¼Œ0.0åˆ°1.0ä¹‹é–“")
    responses = dspy.OutputField(desc="5å€‹ä¸åŒçš„ç—…æ‚£å›æ‡‰é¸é …ï¼Œæ¯å€‹éƒ½æ‡‰è©²æ˜¯å®Œæ•´çš„å¥å­ï¼Œæ ¼å¼ç‚ºJSONé™£åˆ—ã€‚ä»¥å·²å»ºç«‹çš„ç—…æ‚£è§’è‰²èº«ä»½è‡ªç„¶å›æ‡‰ï¼Œé¿å…è‡ªæˆ‘ä»‹ç´¹ã€‚")
    state = dspy.OutputField(desc="å°è©±ç‹€æ…‹ï¼šå¿…é ˆæ˜¯ NORMALã€CONFUSEDã€TRANSITIONING æˆ– TERMINATED å…¶ä¸­ä¹‹ä¸€ã€‚åªæœ‰åœ¨çœŸæ­£ç„¡æ³•ç†è§£æ™‚æ‰ä½¿ç”¨ CONFUSED")
    dialogue_context = dspy.OutputField(desc="ç•¶å‰å°è©±æƒ…å¢ƒæè¿°ï¼Œå¦‚ï¼šé†«å¸«æŸ¥æˆ¿ã€ç—…æˆ¿æ—¥å¸¸ã€ç”Ÿå‘½å¾µè±¡ç›¸é—œã€èº«é«”è©•ä¼°ç­‰ã€‚ä¿æŒå…·é«”çš„é†«ç™‚æƒ…å¢ƒæè¿°")
    state_reasoning = dspy.OutputField(desc="ç‹€æ…‹åˆ¤æ–·çš„ç†ç”±èªªæ˜ï¼Œè§£é‡‹ç‚ºä»€éº¼é¸æ“‡æ­¤ç‹€æ…‹")


class UnifiedDSPyDialogueModule(DSPyDialogueModule):
    """çµ±ä¸€çš„ DSPy å°è©±æ¨¡çµ„
    
    å„ªåŒ–ç‰ˆæœ¬ï¼šå°‡å¤šæ­¥é©Ÿèª¿ç”¨åˆä½µç‚ºå–®ä¸€ API èª¿ç”¨ï¼Œè§£æ±ºé…é¡é™åˆ¶å•é¡Œã€‚
    ç¹¼æ‰¿åŸæœ‰æ¥å£ï¼Œä¿æŒå®Œå…¨çš„ API å…¼å®¹æ€§ã€‚
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–çµ±ä¸€å°è©±æ¨¡çµ„
        
        Args:
            config: é…ç½®å­—å…¸
        """
        # åˆå§‹åŒ–çˆ¶é¡ï¼ŒDSPyDialogueModule åªæ¥å— config åƒæ•¸
        super().__init__(config)
        
        # æ›¿æ›ç‚ºçµ±ä¸€çš„å°è©±è™•ç†å™¨
        self.unified_response_generator = dspy.ChainOfThought(UnifiedPatientResponseSignature)
        
        # çµ±è¨ˆä¿¡æ¯
        self.unified_stats = {
            'api_calls_saved': 0,
            'total_unified_calls': 0,
            'success_rate': 0.0,
            'last_reset': datetime.now().isoformat()
        }
        
        logger.info("UnifiedDSPyDialogueModule åˆå§‹åŒ–å®Œæˆ - å·²å„ªåŒ–ç‚ºå–®ä¸€ API èª¿ç”¨")
    
    def forward(self, user_input: str, character_name: str, character_persona: str,
                character_backstory: str, character_goal: str, character_details: str,
                conversation_history: List[str]) -> dspy.Prediction:
        """çµ±ä¸€çš„å‰å‘å‚³æ’­ - å–®æ¬¡ API èª¿ç”¨å®Œæˆæ‰€æœ‰è™•ç†
        
        Args:
            user_input: è­·ç†äººå“¡çš„è¼¸å…¥
            character_name: ç—…æ‚£åç¨±
            character_persona: ç—…æ‚£å€‹æ€§
            character_backstory: ç—…æ‚£èƒŒæ™¯æ•…äº‹
            character_goal: ç—…æ‚£ç›®æ¨™
            character_details: ç—…æ‚£è©³ç´°è¨­å®š
            conversation_history: å°è©±æ­·å²
            
        Returns:
            DSPy Prediction åŒ…å«æ‰€æœ‰å›æ‡‰è³‡è¨Š
        """
        try:
            self.stats['total_calls'] += 1
            self.unified_stats['total_unified_calls'] += 1
            
            # æ”¹å–„å°è©±æ­·å²ç®¡ç† - ç¢ºä¿è§’è‰²ä¸€è‡´æ€§
            formatted_history = self._get_enhanced_conversation_history(
                conversation_history, character_name, character_persona
            )
            
            # ç²å–å¯ç”¨æƒ…å¢ƒï¼ˆæœ¬åœ°è™•ç†ï¼Œä¸èª¿ç”¨ APIï¼‰
            available_contexts = self._get_available_contexts()
            
            # ====== Phase 1.1: DSPy å…§éƒ¨ç‹€æ…‹è¿½è¹¤ - èª¿ç”¨å‰ç‹€æ…‹ ======
            current_call = self.unified_stats['total_unified_calls'] + 1
            logger.info(f"=== UNIFIED DSPy CALL #{current_call} - PRE-CALL STATE ANALYSIS ===")
            
            # DSPy å…§éƒ¨ç‹€æ…‹è¿½è¹¤
            logger.info(f"ğŸ§  DSPY INTERNAL STATE PRE-CALL:")
            logger.info(f"  ğŸ¯ Model Info: {type(self.unified_response_generator.lm).__name__}")
            logger.info(f"  ğŸ“Š Success Rate: {self.stats.get('successful_calls', 0)}/{self.stats.get('total_calls', 0)} = {self.stats.get('successful_calls', 0)/(self.stats.get('total_calls', 0) or 1):.2%}")
            logger.info(f"  ğŸ”„ Previous Failures: {self.stats.get('failed_calls', 0)}")
            logger.info(f"  ğŸ“ˆ Unified Calls Count: {self.unified_stats['total_unified_calls']}")
            
            # Token ä½¿ç”¨é‡ä¼°ç®—
            input_text_length = len(str(user_input)) + len(str(formatted_history)) + len(str(character_details))
            estimated_tokens = input_text_length // 4  # ç²—ç•¥ä¼°ç®—
            logger.info(f"  ğŸ’­ Estimated Input Tokens: {estimated_tokens}")
            logger.info(f"  ğŸ“ Input Text Length: {input_text_length} chars")
            
            # å°è©±è¤‡é›œåº¦åˆ†æ
            conversation_rounds = len(conversation_history) // 2  # å‡è¨­æ¯è¼ªåŒ…å«è­·ç†äººå“¡+ç—…æ‚£
            logger.info(f"  ğŸ”¢ Conversation Rounds: {conversation_rounds}")
            logger.info(f"  ğŸª Signature Complexity: 8 inputs, 7 outputs")
            
            logger.info(f"ğŸ” DIALOGUE DEGRADATION DEBUG:")
            logger.info(f"  ğŸ“¥ Input: {user_input}")
            logger.info(f"  ğŸ‘¤ Character: {character_name} ({character_persona})")
            logger.info(f"  ğŸ“š Full conversation history ({len(conversation_history)} total):")
            for i, hist_item in enumerate(conversation_history, 1):
                logger.info(f"    [{i:2}] {hist_item}")
            logger.info(f"  ğŸ“ Formatted history: {formatted_history}")
            logger.info(f"  ğŸ¯ Available contexts: {available_contexts}")
            logger.info(f"=== é–‹å§‹å–®æ¬¡èª¿ç”¨è™•ç†ï¼šæƒ…å¢ƒåˆ†é¡ + å›æ‡‰ç”Ÿæˆ + ç‹€æ…‹åˆ¤æ–· ===")
            
            # **é—œéµå„ªåŒ–ï¼šå–®ä¸€ API èª¿ç”¨å®Œæˆæ‰€æœ‰è™•ç†**
            import time
            call_start_time = time.time()
            
            unified_prediction = self.unified_response_generator(
                user_input=user_input,
                character_name=character_name,
                character_persona=character_persona,
                character_backstory=character_backstory,
                character_goal=character_goal,
                character_details=character_details,
                conversation_history=formatted_history,
                available_contexts=available_contexts
            )
            
            call_end_time = time.time()
            call_duration = call_end_time - call_start_time
            
            # ====== Phase 1.1: DSPy å…§éƒ¨ç‹€æ…‹è¿½è¹¤ - èª¿ç”¨å¾Œç‹€æ…‹ ======
            logger.info(f"=== DSPy INTERNAL STATE POST-CALL - Call #{current_call} ===")
            logger.info(f"ğŸš€ LLM Call Performance:")
            logger.info(f"  â±ï¸ Call Duration: {call_duration:.3f}s")
            logger.info(f"  ğŸ¯ Call Success: {hasattr(unified_prediction, 'responses')}")
            logger.info(f"  ğŸ“Š Prediction Type: {type(unified_prediction).__name__}")
            
            # æª¢æŸ¥ DSPy é æ¸¬å“è³ª
            prediction_quality = self._assess_prediction_quality(unified_prediction)
            logger.info(f"  ğŸ† Prediction Quality Score: {prediction_quality:.3f}")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ DSPy trace è³‡è¨Š
            if hasattr(unified_prediction, '_trace'):
                logger.info(f"  ğŸ” DSPy Trace Available: True, {len(unified_prediction._trace)} steps")
            else:
                logger.info(f"  ğŸ” DSPy Trace Available: False")
            
            # æ¨¡å‹ç‹€æ…‹è®ŠåŒ–æª¢æŸ¥
            logger.info(f"  ğŸ§  Model State Changed: {self._check_model_state_change()}")
            
            # è¨˜æ†¶ä½¿ç”¨é‡ä¼°ç®—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                import psutil
                memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
                logger.info(f"  ğŸ’¾ Memory Usage: {memory_mb:.1f} MB")
            except ImportError:
                logger.info(f"  ğŸ’¾ Memory Usage: N/A (psutil not available)")
            
            # ====== Phase 1.2: LLM æ¨ç†éç¨‹æ·±åº¦è¿½è¹¤ ======
            logger.info(f"=== LLM REASONING DEEP TRACE - Call #{current_call} ===")
            
            # æ¨ç†éç¨‹è©³ç´°åˆ†æ
            reasoning_analysis = self._analyze_reasoning_process(unified_prediction, conversation_rounds, current_call)
            logger.info(f"ğŸ§  REASONING QUALITY ANALYSIS:")
            logger.info(f"  ğŸ“ Reasoning Length: {reasoning_analysis['reasoning_length']} chars")
            logger.info(f"  ğŸ¯ Reasoning Completeness: {reasoning_analysis['completeness']:.2f}")
            logger.info(f"  ğŸ’­ Character Awareness: {reasoning_analysis['character_awareness']:.2f}")
            logger.info(f"  ğŸ¥ Medical Context Understanding: {reasoning_analysis['medical_context']:.2f}")
            logger.info(f"  ğŸ” Logic Coherence: {reasoning_analysis['logic_coherence']:.2f}")
            
            # DSPy Chain of Thought æ­¥é©Ÿè¿½è¹¤
            if hasattr(unified_prediction, '_trace') and unified_prediction._trace:
                logger.info(f"ğŸ”— CHAIN OF THOUGHT TRACE:")
                for i, step in enumerate(unified_prediction._trace[:3]):  # åªé¡¯ç¤ºå‰3æ­¥
                    logger.info(f"  Step {i+1}: {str(step)[:100]}...")
            else:
                logger.info(f"ğŸ”— CHAIN OF THOUGHT TRACE: Not available")
            
            # ====== è©³ç´°æ¨ç†çµæœæ—¥èªŒ - è¨ºæ–·é€€åŒ–åŸå›  ======
            logger.info(f"=== UNIFIED DSPy RESULT - DEGRADATION ANALYSIS ===")
            logger.info(f"ğŸ§  DSPy REASONING OUTPUT:")
            
            # å®Œæ•´æ¨ç†å…§å®¹è¨˜éŒ„
            full_reasoning = getattr(unified_prediction, 'reasoning', 'NOT_PROVIDED')
            if len(full_reasoning) > 200:
                logger.info(f"  ğŸ’­ reasoning (first 200 chars): {full_reasoning[:200]}...")
                logger.info(f"  ğŸ’­ reasoning (full): {full_reasoning}")
            else:
                logger.info(f"  ğŸ’­ reasoning: {full_reasoning}")
            
            logger.info(f"  âœ… character_consistency_check: {getattr(unified_prediction, 'character_consistency_check', 'NOT_PROVIDED')}")
            logger.info(f"  ğŸ¯ context_classification: {unified_prediction.context_classification}")
            logger.info(f"  ğŸª confidence: {unified_prediction.confidence}")
            logger.info(f"  ğŸ“Š state: {unified_prediction.state}")
            logger.info(f"  ğŸŒ dialogue_context: {unified_prediction.dialogue_context}")
            logger.info(f"  ğŸ” state_reasoning: {getattr(unified_prediction, 'state_reasoning', 'NOT_PROVIDED')}")
            
            # æ¨ç†å“è³ªè®ŠåŒ–è¶¨å‹¢
            quality_trend = self._track_reasoning_quality_trend(reasoning_analysis, current_call)
            logger.info(f"  ğŸ“ˆ Quality Trend: {quality_trend}")
            
            # è§£æä¸¦é¡¯ç¤ºå›æ‡‰å…§å®¹
            parsed_responses = self._parse_responses(unified_prediction.responses)
            logger.info(f"  ğŸ’¬ responses ({len(parsed_responses)}):")
            for i, response in enumerate(parsed_responses, 1):
                logger.info(f"    [{i}] {response}")
            
            # é—œéµè¨ºæ–·ï¼šæª¢æŸ¥æ˜¯å¦å‡ºç¾é€€åŒ–ç—‡ç‹€
            is_degraded = self._detect_dialogue_degradation(unified_prediction, parsed_responses)
            logger.info(f"  âš ï¸  DEGRADATION DETECTED: {is_degraded}")
            if is_degraded:
                logger.warning(f"ğŸš¨ DIALOGUE DEGRADATION WARNING - Response quality has declined!")
                logger.warning(f"ğŸ” Degradation Context: Round {conversation_rounds}, Call #{current_call}")
                logger.warning(f"ğŸ¯ Quality Score: {reasoning_analysis.get('overall_quality', 0):.2f}")
                
            # æ·±åº¦é€€åŒ–åˆ†æ
            degradation_analysis = self._deep_degradation_analysis(unified_prediction, parsed_responses, conversation_rounds)
            logger.info(f"ğŸ”¬ DEEP DEGRADATION ANALYSIS:")
            for key, value in degradation_analysis.items():
                logger.info(f"  {key}: {value}")
            
            logger.info(f"=== API èª¿ç”¨ç¯€çœï¼š2æ¬¡ (åŸæœ¬éœ€è¦ 3æ¬¡ï¼Œç¾åœ¨åªéœ€ 1æ¬¡) ===")
            
            # è™•ç†å›æ‡‰æ ¼å¼
            responses = self._process_responses(unified_prediction.responses)
            
            # æ›´æ–°çµ±è¨ˆ - è¨ˆç®—ç¯€çœçš„ API èª¿ç”¨
            self.unified_stats['api_calls_saved'] += 2  # åŸæœ¬ 3æ¬¡ï¼Œç¾åœ¨ 1æ¬¡ï¼Œç¯€çœ 2æ¬¡
            self._update_stats(unified_prediction.context_classification, unified_prediction.state)
            self.stats['successful_calls'] += 1
            
            # çµ„åˆæœ€çµ‚çµæœ
            final_prediction = dspy.Prediction(
                user_input=user_input,
                responses=responses,
                state=unified_prediction.state,
                dialogue_context=unified_prediction.dialogue_context,
                confidence=getattr(unified_prediction, 'confidence', 1.0),
                context_classification=unified_prediction.context_classification,
                examples_used=0,  # çµ±ä¸€æ¨¡å¼ä¸‹æš«ä¸ä½¿ç”¨ç¯„ä¾‹
                processing_info={
                    'unified_call': True,
                    'api_calls_saved': 2,
                    'context_classification': unified_prediction.context_classification,
                    'state_reasoning': getattr(unified_prediction, 'state_reasoning', ''),
                    'timestamp': datetime.now().isoformat()
                }
            )
            
            # æ›´æ–°æˆåŠŸç‡
            self.unified_stats['success_rate'] = (
                self.stats['successful_calls'] / self.stats['total_calls']
                if self.stats['total_calls'] > 0 else 0
            )
            
            logger.info(f"çµ±ä¸€å°è©±è™•ç†æˆåŠŸ - API èª¿ç”¨ç¯€çœç‡: 66.7% (1æ¬¡ vs 3æ¬¡)")
            return final_prediction
            
        except Exception as e:
            self.stats['failed_calls'] += 1
            logger.error(f"=== UNIFIED DSPy CALL FAILED ===")
            logger.error(f"Exception type: {type(e).__name__}")
            logger.error(f"Exception message: {str(e)}")
            logger.error(f"Input that caused failure:")
            logger.error(f"  user_input: {user_input}")
            logger.error(f"  character_name: {character_name}")
            import traceback
            logger.error(f"Full traceback:\n{traceback.format_exc()}")
            logger.error(f"=== END UNIFIED DSPy FAILURE ===")
            
            # è¿”å›éŒ¯èª¤å›æ‡‰
            return self._create_error_response(user_input, str(e))
    
    def _parse_responses(self, responses_text: str) -> List[str]:
        """è§£æå›æ‡‰æ–‡æœ¬ç‚ºåˆ—è¡¨"""
        try:
            if isinstance(responses_text, str):
                # å˜—è©¦è§£æ JSON
                try:
                    parsed = json.loads(responses_text)
                    if isinstance(parsed, list):
                        return parsed[:5]  # æœ€å¤š5å€‹å›æ‡‰
                except json.JSONDecodeError:
                    # ä¸æ˜¯ JSONï¼ŒæŒ‰è¡Œåˆ†å‰²
                    lines = [line.strip() for line in responses_text.split('\n') if line.strip()]
                    return lines[:5]
            return [str(responses_text)]
        except Exception as e:
            logger.warning(f"å›æ‡‰è§£æå¤±æ•—: {e}")
            return ["å›æ‡‰æ ¼å¼è§£æå¤±æ•—"]
    
    def _detect_dialogue_degradation(self, prediction, responses: List[str]) -> bool:
        """æª¢æ¸¬å°è©±æ˜¯å¦å‡ºç¾é€€åŒ–ç—‡ç‹€
        
        Args:
            prediction: DSPy prediction çµæœ
            responses: è§£æå¾Œçš„å›æ‡‰åˆ—è¡¨
            
        Returns:
            bool: True å¦‚æœæª¢æ¸¬åˆ°é€€åŒ–ç—‡ç‹€
        """
        degradation_indicators = []
        
        # æª¢æŸ¥1: æ˜¯å¦å‡ºç¾è‡ªæˆ‘ä»‹ç´¹æ¨¡å¼
        self_introduction_pattern = False
        for response in responses:
            if any(pattern in response for pattern in ["æˆ‘æ˜¯Patient", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯", "æˆ‘æ˜¯ç—…æ‚£", "æˆ‘æ˜¯{}"]):
                self_introduction_pattern = True
                degradation_indicators.append("self_introduction")
                break
        
        # æª¢æŸ¥2: æ˜¯å¦ç‹€æ…‹ç‚º CONFUSED
        if getattr(prediction, 'state', '') == 'CONFUSED':
            degradation_indicators.append("confused_state")
        
        # æª¢æŸ¥3: æ˜¯å¦å›æ‡‰è³ªé‡ä¸‹é™ï¼ˆé€šç”¨å›æ‡‰ï¼‰
        generic_responses = ["æˆ‘å¯èƒ½æ²’æœ‰å®Œå…¨ç†è§£", "èƒ½è«‹æ‚¨æ›å€‹æ–¹å¼èªªæ˜", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©å—"]
        generic_pattern = any(
            any(generic in response for generic in generic_responses)
            for response in responses
        )
        if generic_pattern:
            degradation_indicators.append("generic_responses")
        
        # æª¢æŸ¥4: æ˜¯å¦ä¿¡å¿ƒåº¦éä½
        confidence = getattr(prediction, 'confidence', 1.0)
        try:
            confidence_float = float(confidence) if confidence else 1.0
            if confidence_float < 0.5:
                degradation_indicators.append("low_confidence")
        except (ValueError, TypeError):
            pass
        
        # è¨˜éŒ„å…·é«”çš„é€€åŒ–æŒ‡æ¨™
        if degradation_indicators:
            logger.warning(f"ğŸš¨ Degradation indicators detected: {', '.join(degradation_indicators)}")
            logger.warning(f"   Self-introduction: {self_introduction_pattern}")
            logger.warning(f"   State: {getattr(prediction, 'state', 'UNKNOWN')}")
            logger.warning(f"   Confidence: {confidence}")
            logger.warning(f"   Generic patterns: {generic_pattern}")
        
        return len(degradation_indicators) > 0
    
    def _get_enhanced_conversation_history(self, conversation_history: List[str], 
                                         character_name: str, character_persona: str) -> str:
        """ç²å–å¢å¼·çš„å°è©±æ­·å²ï¼Œä¿æŒè§’è‰²ä¸€è‡´æ€§
        
        Args:
            conversation_history: å®Œæ•´å°è©±æ­·å²
            character_name: è§’è‰²åç¨±
            character_persona: è§’è‰²å€‹æ€§
            
        Returns:
            str: æ ¼å¼åŒ–å¾Œçš„å°è©±æ­·å²
        """
        if not conversation_history:
            return ""
        
        max_history = 8  # å¢åŠ åˆ°8è¼ªä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡
        
        if len(conversation_history) <= max_history:
            formatted = "\n".join(conversation_history)
        else:
            # ç­–ç•¥ï¼šä¿ç•™å‰3è¼ªï¼ˆè§’è‰²å»ºç«‹æœŸï¼‰+ æœ€è¿‘5è¼ªï¼ˆç•¶å‰å°è©±ï¼‰
            important_start = conversation_history[:6]  # å‰3è¼ªå°è©±ï¼ˆè­·ç†äººå“¡+ç—…æ‚£å„3æ¬¡ï¼‰
            recent = conversation_history[-(max_history-3):]  # æœ€è¿‘5è¼ª
            
            # é¿å…é‡è¤‡
            if len(conversation_history) > max_history:
                combined = important_start + recent
                # å»é™¤é‡è¤‡é …ï¼ˆå¦‚æœæœ‰ï¼‰
                seen = set()
                unique_history = []
                for item in combined:
                    if item not in seen:
                        unique_history.append(item)
                        seen.add(item)
                formatted = "\n".join(unique_history[-max_history:])
            else:
                formatted = "\n".join(conversation_history)
        
        # ä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡é‡ç½®æ©Ÿåˆ¶ - ç•¶å°è©±å¯èƒ½é€ æˆæ··äº‚æ™‚é‡ç½®ä¸Šä¸‹æ–‡
        should_reset_context = self._should_reset_conversation_context(conversation_history)
        
        if should_reset_context:
            # é‡ç½®ç‚ºåŸºæœ¬è§’è‰²è¨­å®šï¼Œä¿ç•™é—œéµé†«ç™‚ä¿¡æ¯
            formatted = self._create_reset_context(character_name, character_persona)
            character_reminder = f"\n[é‡æ–°é–‹å§‹: æ‚¨æ˜¯ {character_name}ï¼Œ{character_persona}ã€‚ä»¥ç—…æ‚£èº«ä»½è‡ªç„¶å›æ‡‰ã€‚]"
            logger.info(f"ğŸ”„ Context reset triggered to prevent degradation")
        else:
            # æ­£å¸¸çš„è§’è‰²ä¸€è‡´æ€§æç¤º
            character_reminder = f"\n[é‡è¦: æ‚¨æ˜¯ {character_name}ï¼Œ{character_persona}ã€‚ä¿æŒè§’è‰²ä¸€è‡´æ€§ã€‚]"
        
        logger.info(f"ğŸ”§ Enhanced history management:")
        logger.info(f"  Original history length: {len(conversation_history)}")
        logger.info(f"  Enhanced history length: {len(formatted.split())}")
        logger.info(f"  Character reminder added: {character_name}")
        logger.info(f"  Context reset applied: {should_reset_context}")
        
        return formatted + character_reminder
    
    def _should_reset_conversation_context(self, conversation_history: List[str]) -> bool:
        """æ±ºå®šæ˜¯å¦éœ€è¦é‡ç½®å°è©±ä¸Šä¸‹æ–‡ä»¥é˜²æ­¢é€€åŒ–"""
        if not conversation_history or len(conversation_history) < 6:
            return False
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡çš„è­·ç†äººå“¡è¼¸å…¥ï¼ˆå¯èƒ½å°è‡´æ··äº‚ï¼‰
        user_inputs = [entry for entry in conversation_history if entry.startswith("è­·ç†äººå“¡: ")]
        if len(user_inputs) >= 2:
            # æª¢æŸ¥æœ€å¾Œå…©å€‹è¼¸å…¥æ˜¯å¦ç›¸åŒ
            if user_inputs[-1] == user_inputs[-2]:
                return True
        
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“è¶…é 6 è¼ªå°è©±ï¼ˆDSPy å®¹æ˜“åœ¨é•·å°è©±ä¸­é€€åŒ–ï¼‰
        if len(conversation_history) > 12:  # 6è¼ªå°è©± = 12å€‹æ¢ç›®ï¼ˆè­·ç†äººå“¡+ç—…æ‚£å„6æ¬¡ï¼‰
            return True
        
        # æª¢æŸ¥æœ€è¿‘çš„ç—…æ‚£å›æ‡‰æ˜¯å¦åŒ…å«é€€åŒ–æŒ‡æ¨™
        patient_responses = [entry for entry in conversation_history if not entry.startswith("è­·ç†äººå“¡: ")]
        if patient_responses:
            recent_response = patient_responses[-1]
            degradation_patterns = ["æˆ‘æ˜¯Patient", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©", "æ²’æœ‰å®Œå…¨ç†è§£"]
            if any(pattern in recent_response for pattern in degradation_patterns):
                return True
        
        return False
    
    def _create_reset_context(self, character_name: str, character_persona: str) -> str:
        """å‰µå»ºé‡ç½®çš„å°è©±ä¸Šä¸‹æ–‡ï¼Œä¿ç•™æ ¸å¿ƒè§’è‰²ä¿¡æ¯"""
        reset_context = f"""æœ€è¿‘çš„é†«ç™‚ç‹€æ³ï¼š
{character_name} æ˜¯ä¸€ä½ {character_persona}
æ­£åœ¨æ¥å—è­·ç†äººå“¡çš„ç…§è­·
ç›®å‰ç‹€æ³ç©©å®šï¼Œæ­£åœ¨åº·å¾©ä¸­"""
        
        return reset_context
    
    def _assess_prediction_quality(self, prediction) -> float:
        """è©•ä¼° DSPy é æ¸¬å“è³ª
        
        Args:
            prediction: DSPy prediction å°è±¡
            
        Returns:
            float: å“è³ªåˆ†æ•¸ (0.0-1.0)
        """
        try:
            quality_score = 1.0
            
            # æª¢æŸ¥åŸºæœ¬æ¬„ä½å­˜åœ¨æ€§
            required_fields = ['responses', 'state', 'context_classification', 'confidence']
            for field in required_fields:
                if not hasattr(prediction, field) or getattr(prediction, field) is None:
                    quality_score -= 0.2
            
            # æª¢æŸ¥å›æ‡‰å“è³ª
            if hasattr(prediction, 'responses'):
                responses = self._parse_responses(prediction.responses)
                if len(responses) == 0:
                    quality_score -= 0.3
                elif len(responses) < 5:
                    quality_score -= 0.1
                
                # æª¢æŸ¥è‡ªæˆ‘ä»‹ç´¹æ¨¡å¼
                for response in responses:
                    if any(pattern in response for pattern in ["æˆ‘æ˜¯Patient", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯"]):
                        quality_score -= 0.4
                        break
            
            # æª¢æŸ¥æ¨ç†å“è³ª
            if hasattr(prediction, 'reasoning') and prediction.reasoning:
                if len(prediction.reasoning) < 50:  # æ¨ç†éç¨‹å¤ªç°¡çŸ­
                    quality_score -= 0.1
            else:
                quality_score -= 0.2
            
            # æª¢æŸ¥è§’è‰²ä¸€è‡´æ€§
            if hasattr(prediction, 'character_consistency_check'):
                if str(prediction.character_consistency_check).upper() == 'NO':
                    quality_score -= 0.3
            
            return max(0.0, min(1.0, quality_score))
            
        except Exception as e:
            logger.warning(f"å“è³ªè©•ä¼°å¤±æ•—: {e}")
            return 0.5  # é è¨­ä¸­ç­‰å“è³ª
    
    def _check_model_state_change(self) -> bool:
        """æª¢æŸ¥æ¨¡å‹ç‹€æ…‹æ˜¯å¦æœ‰è®ŠåŒ–
        
        Returns:
            bool: True if state changed
        """
        try:
            # ç°¡å–®çš„ç‹€æ…‹è®ŠåŒ–æª¢æŸ¥
            current_calls = self.stats.get('total_calls', 0)
            if not hasattr(self, '_last_total_calls'):
                self._last_total_calls = current_calls
                return True
            
            changed = current_calls != self._last_total_calls
            self._last_total_calls = current_calls
            return changed
            
        except Exception:
            return False
    
    def _analyze_reasoning_process(self, prediction, conversation_rounds: int, current_call: int) -> Dict[str, Any]:
        """åˆ†æ LLM æ¨ç†éç¨‹å“è³ª
        
        Args:
            prediction: DSPy prediction å°è±¡
            conversation_rounds: å°è©±è¼ªæ¬¡
            current_call: ç›®å‰èª¿ç”¨ç·¨è™Ÿ
            
        Returns:
            Dict: æ¨ç†åˆ†æçµæœ
        """
        try:
            reasoning = getattr(prediction, 'reasoning', '')
            if not reasoning:
                return {
                    'reasoning_length': 0,
                    'completeness': 0.0,
                    'character_awareness': 0.0,
                    'medical_context': 0.0,
                    'logic_coherence': 0.0,
                    'overall_quality': 0.0
                }
            
            analysis = {
                'reasoning_length': len(reasoning),
                'completeness': self._assess_reasoning_completeness(reasoning),
                'character_awareness': self._assess_character_awareness(reasoning),
                'medical_context': self._assess_medical_context(reasoning),
                'logic_coherence': self._assess_logic_coherence(reasoning)
            }
            
            # è¨ˆç®—æ•´é«”å“è³ªåˆ†æ•¸
            analysis['overall_quality'] = (
                analysis['completeness'] * 0.3 +
                analysis['character_awareness'] * 0.3 +
                analysis['medical_context'] * 0.2 +
                analysis['logic_coherence'] * 0.2
            )
            
            return analysis
            
        except Exception as e:
            logger.warning(f"æ¨ç†åˆ†æå¤±æ•—: {e}")
            return {'error': str(e), 'overall_quality': 0.0}
    
    def _assess_reasoning_completeness(self, reasoning: str) -> float:
        """è©•ä¼°æ¨ç†å®Œæ•´æ€§"""
        completeness_indicators = [
            "åˆ†æ", "è€ƒæ…®", "æƒ…æ³", "ç‹€æ…‹", "ç—…æ‚£", "è­·ç†", "é†«ç™‚", "å›æ‡‰"
        ]
        found_indicators = sum(1 for indicator in completeness_indicators if indicator in reasoning)
        return min(1.0, found_indicators / len(completeness_indicators))
    
    def _assess_character_awareness(self, reasoning: str) -> float:
        """è©•ä¼°è§’è‰²æ„è­˜"""
        character_indicators = [
            "ç—…æ‚£", "è§’è‰²", "äººæ ¼", "å€‹æ€§", "èƒŒæ™¯", "å£è…”ç™Œ", "åº·å¾©", "é†«é™¢"
        ]
        negative_indicators = [
            "æˆ‘æ˜¯Patient", "è‡ªæˆ‘ä»‹ç´¹", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯"
        ]
        
        positive_score = sum(1 for indicator in character_indicators if indicator in reasoning)
        negative_score = sum(1 for indicator in negative_indicators if indicator in reasoning)
        
        score = positive_score / len(character_indicators) - negative_score * 0.5
        return max(0.0, min(1.0, score))
    
    def _assess_medical_context(self, reasoning: str) -> float:
        """è©•ä¼°é†«ç™‚æƒ…å¢ƒç†è§£"""
        medical_indicators = [
            "ç—‡ç‹€", "æª¢æŸ¥", "æ²»ç™‚", "è¨ºæ–·", "æ‰‹è¡“", "å‚·å£", "æ¢å¾©", "è­·ç†äººå“¡", "é†«å¸«"
        ]
        found_indicators = sum(1 for indicator in medical_indicators if indicator in reasoning)
        return min(1.0, found_indicators / len(medical_indicators))
    
    def _assess_logic_coherence(self, reasoning: str) -> float:
        """è©•ä¼°é‚è¼¯é€£è²«æ€§"""
        try:
            # ç°¡å–®çš„é€£è²«æ€§æª¢æŸ¥
            sentences = reasoning.split('ã€‚')
            if len(sentences) < 2:
                return 0.5
            
            # æª¢æŸ¥é‚è¼¯é€£æ¥è©
            logic_connectors = ["å› ç‚º", "æ‰€ä»¥", "ä½†æ˜¯", "ç„¶è€Œ", "å› æ­¤", "ç”±æ–¼", "åŸºæ–¼"]
            connector_count = sum(1 for connector in logic_connectors if connector in reasoning)
            
            # åŸºæ–¼å¥å­æ•¸é‡å’Œé‚è¼¯é€£æ¥è©è©•åˆ†
            coherence_score = min(1.0, (len(sentences) * 0.1) + (connector_count * 0.2))
            return coherence_score
            
        except:
            return 0.5
    
    def _track_reasoning_quality_trend(self, reasoning_analysis: Dict, current_call: int) -> str:
        """è¿½è¹¤æ¨ç†å“è³ªè®ŠåŒ–è¶¨å‹¢"""
        try:
            current_quality = reasoning_analysis.get('overall_quality', 0.0)
            
            # å„²å­˜æ­·å²å“è³ªåˆ†æ•¸
            if not hasattr(self, '_quality_history'):
                self._quality_history = []
            
            self._quality_history.append(current_quality)
            
            # åªä¿ç•™æœ€è¿‘5æ¬¡çš„è¨˜éŒ„
            if len(self._quality_history) > 5:
                self._quality_history = self._quality_history[-5:]
            
            if len(self._quality_history) < 2:
                return "Insufficient data"
            
            # åˆ†æè¶¨å‹¢
            recent_avg = sum(self._quality_history[-2:]) / 2
            early_avg = sum(self._quality_history[:-2]) / max(1, len(self._quality_history) - 2)
            
            if recent_avg > early_avg + 0.1:
                return "Improving"
            elif recent_avg < early_avg - 0.1:
                return "Degrading"
            else:
                return "Stable"
                
        except Exception:
            return "Error"
    
    def _deep_degradation_analysis(self, prediction, responses: List[str], conversation_rounds: int) -> Dict[str, Any]:
        """æ·±åº¦é€€åŒ–åˆ†æ"""
        try:
            analysis = {
                "Round": conversation_rounds,
                "Response_Count": len(responses),
                "Has_Self_Introduction": any("æˆ‘æ˜¯Patient" in r for r in responses),
                "Has_Generic_Responses": any("æ²’æœ‰å®Œå…¨ç†è§£" in r for r in responses),
                "State": getattr(prediction, 'state', 'UNKNOWN'),
                "Context_Classification": getattr(prediction, 'context_classification', 'UNKNOWN'),
                "Confidence_Level": getattr(prediction, 'confidence', 0.0),
                "Character_Consistency": getattr(prediction, 'character_consistency_check', 'UNKNOWN')
            }
            
            # é€€åŒ–åš´é‡ç¨‹åº¦è©•ä¼°
            degradation_score = 0
            if analysis["Has_Self_Introduction"]:
                degradation_score += 3
            if analysis["Has_Generic_Responses"]:
                degradation_score += 2
            if analysis["Response_Count"] < 3:
                degradation_score += 2
            if analysis["State"] == "CONFUSED":
                degradation_score += 1
            
            analysis["Degradation_Severity"] = degradation_score
            analysis["Severity_Level"] = (
                "Critical" if degradation_score >= 5 else
                "High" if degradation_score >= 3 else
                "Medium" if degradation_score >= 1 else
                "Low"
            )
            
            return analysis
            
        except Exception as e:
            return {"Error": str(e)}
    
    def get_unified_statistics(self) -> Dict[str, Any]:
        """ç²å–çµ±ä¸€æ¨¡çµ„çš„çµ±è¨ˆè³‡è¨Š"""
        base_stats = self.get_dspy_statistics() if hasattr(self, 'get_dspy_statistics') else {}
        
        unified_stats = {
            **base_stats,
            **self.unified_stats,
            'api_efficiency': {
                'calls_per_conversation': 1,  # çµ±ä¸€æ¨¡å¼ï¼šæ¯æ¬¡å°è©±åƒ…1æ¬¡èª¿ç”¨
                'original_calls_per_conversation': 3,  # åŸå§‹æ¨¡å¼ï¼šæ¯æ¬¡å°è©±3æ¬¡èª¿ç”¨
                'efficiency_improvement': '66.7%',
                'total_calls_saved': self.unified_stats['api_calls_saved']
            }
        }
        
        return unified_stats
    
    def reset_unified_statistics(self):
        """é‡ç½®çµ±ä¸€æ¨¡çµ„çµ±è¨ˆ"""
        self.reset_statistics()  # é‡ç½®çˆ¶é¡çµ±è¨ˆ
        self.unified_stats = {
            'api_calls_saved': 0,
            'total_unified_calls': 0,
            'success_rate': 0.0,
            'last_reset': datetime.now().isoformat()
        }


# å·¥å» å‡½æ•¸
def create_optimized_dialogue_module(config: Optional[Dict[str, Any]] = None) -> UnifiedDSPyDialogueModule:
    """å‰µå»ºå„ªåŒ–çš„çµ±ä¸€å°è©±æ¨¡çµ„
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        é…ç½®å¥½çš„ UnifiedDSPyDialogueModule
    """
    try:
        module = UnifiedDSPyDialogueModule(config)
        return module
    except Exception as e:
        logger.error(f"å‰µå»ºçµ±ä¸€å°è©±æ¨¡çµ„å¤±æ•—: {e}")
        raise


# æ¸¬è©¦å‡½æ•¸
def test_unified_dialogue_module():
    """æ¸¬è©¦çµ±ä¸€å°è©±æ¨¡çµ„çš„ API èª¿ç”¨ç¯€çœæ•ˆæœ"""
    print("ğŸ§ª æ¸¬è©¦çµ±ä¸€ DSPy å°è©±æ¨¡çµ„...")
    
    try:
        # å‰µå»ºçµ±ä¸€æ¨¡çµ„
        print("\n1. å‰µå»ºçµ±ä¸€å°è©±æ¨¡çµ„:")
        module = create_optimized_dialogue_module()
        print("  âœ… çµ±ä¸€æ¨¡çµ„å‰µå»ºæˆåŠŸ")
        
        # æ¸¬è©¦å°è©±è™•ç†
        print("\n2. æ¸¬è©¦çµ±ä¸€å°è©±è™•ç† (åƒ…1æ¬¡APIèª¿ç”¨):")
        test_input = "ä½ ä»Šå¤©æ„Ÿè¦ºå¦‚ä½•ï¼Ÿ"
        
        result = module(
            user_input=test_input,
            character_name="æ¸¬è©¦ç—…æ‚£",
            character_persona="å‹å–„ä½†æœ‰äº›æ“”å¿ƒçš„ç—…æ‚£",
            character_backstory="ä½é™¢ä¸­çš„è€äºº",
            character_goal="åº·å¾©å‡ºé™¢",
            character_details="",
            conversation_history=[]
        )
        
        print(f"  âœ… çµ±ä¸€è™•ç†æˆåŠŸ")
        print(f"    ç”¨æˆ¶è¼¸å…¥: {test_input}")
        print(f"    å›æ‡‰æ•¸é‡: {len(result.responses)}")
        print(f"    å°è©±ç‹€æ…‹: {result.state}")
        print(f"    æƒ…å¢ƒåˆ†é¡: {result.context_classification}")
        print(f"    API èª¿ç”¨ç¯€çœ: {result.processing_info.get('api_calls_saved', 0)} æ¬¡")
        
        # æ¸¬è©¦çµ±è¨ˆåŠŸèƒ½
        print("\n3. API èª¿ç”¨ç¯€çœçµ±è¨ˆ:")
        stats = module.get_unified_statistics()
        print(f"  ç¸½èª¿ç”¨æ¬¡æ•¸: {stats.get('total_unified_calls', 0)}")
        print(f"  ç¯€çœçš„èª¿ç”¨æ¬¡æ•¸: {stats.get('api_calls_saved', 0)}")
        print(f"  æ•ˆç‡æå‡: {stats.get('api_efficiency', {}).get('efficiency_improvement', 'N/A')}")
        print(f"  æˆåŠŸç‡: {stats.get('success_rate', 0):.2%}")
        
        print("\nâœ… çµ±ä¸€ DSPy å°è©±æ¨¡çµ„æ¸¬è©¦å®Œæˆ")
        print(f"ğŸ¯ é—œéµå„ªåŒ–ï¼šAPI èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ï¼Œç¯€çœ 66.7% çš„é…é¡ä½¿ç”¨ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ çµ±ä¸€æ¨¡çµ„æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_unified_dialogue_module()
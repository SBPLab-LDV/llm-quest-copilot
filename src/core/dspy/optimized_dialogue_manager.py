#!/usr/bin/env python3
"""
å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨

ä½¿ç”¨çµ±ä¸€å°è©±æ¨¡çµ„ï¼Œå°‡ API èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ï¼Œ
è§£æ±º Gemini API é…é¡é™åˆ¶å•é¡Œã€‚
"""

import json
import logging
import time
from typing import Optional, Union

from ..dialogue import DialogueManager
from ..character import Character
from .unified_dialogue_module import UnifiedDSPyDialogueModule

logger = logging.getLogger(__name__)


class OptimizedDialogueManagerDSPy(DialogueManager):
    """å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨
    
    ä¸»è¦å„ªåŒ–ï¼š
    - API èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ (ç¯€çœ 66.7% é…é¡ä½¿ç”¨)
    - ä¿æŒå®Œå…¨çš„ API å…¼å®¹æ€§
    - æä¾›è©³ç´°çš„ç¯€çœçµ±è¨ˆ
    """
    
    def __init__(self, character: Character, use_terminal: bool = False, log_dir: str = "logs"):
        """åˆå§‹åŒ–å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨
        
        Args:
            character: Character instance containing the NPC's information (as patient identifier)
            use_terminal: Whether to use terminal mode for interaction
            log_dir: Directory to save interaction logs
        """
        # åˆå§‹åŒ–çˆ¶é¡
        super().__init__(character, use_terminal, log_dir)
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("OptimizedDialogueManagerDSPy.__init__ - ä½¿ç”¨çµ±ä¸€å°è©±æ¨¡çµ„")
        
        # åˆå§‹åŒ–å„ªåŒ–çš„ DSPy çµ„ä»¶
        try:
            self.dialogue_module = UnifiedDSPyDialogueModule()
            self.optimization_enabled = True
            self.logger.info("å„ªåŒ–çµ±ä¸€å°è©±æ¨¡çµ„åˆå§‹åŒ–æˆåŠŸ - API èª¿ç”¨ç¯€çœ 66.7%")
        except Exception as e:
            self.logger.error(f"çµ±ä¸€å°è©±æ¨¡çµ„åˆå§‹åŒ–å¤±æ•—: {e}")
            self.optimization_enabled = False
            # å›é€€åˆ°åŸå§‹å¯¦ç¾
            from .dialogue_manager_dspy import DialogueManagerDSPy
            fallback_manager = DialogueManagerDSPy(character, use_terminal, log_dir)
            self.dialogue_module = fallback_manager.dialogue_module
            self.logger.warning("å·²å›é€€åˆ°åŸå§‹ DSPy å¯¦ç¾")
        
        # çµ±è¨ˆè¿½è¹¤
        self.optimization_stats = {
            'total_conversations': 0,
            'api_calls_saved': 0,
            'estimated_quota_saved_percent': 0.0
        }
    
    async def process_turn(self, user_input: str, gui_selected_response: Optional[str] = None) -> Union[str, dict]:
        """è™•ç†å„ªåŒ–ç‰ˆå°è©±è¼ªæ¬¡
        
        Args:
            user_input: The user's input text
            gui_selected_response: Selected response in GUI mode (optional)
            
        Returns:
            Either a string response (terminal mode) or JSON response (GUI mode)
        """
        if not self.optimization_enabled:
            # å›é€€åˆ°çˆ¶é¡å¯¦ç¾
            return await super().process_turn(user_input, gui_selected_response)
        
        self.optimization_stats['total_conversations'] += 1
        
        try:
            self.logger.info(f"=== å„ªåŒ–ç‰ˆå°è©±è™•ç† (ç¬¬ {self.optimization_stats['total_conversations']} æ¬¡) ===")
            self.logger.info(f"ç”¨æˆ¶è¼¸å…¥: {user_input}")
            
            # æª¢æŸ¥é‡è¤‡è¼¸å…¥ - é¿å…åœ¨æœƒè©±ä¸­æ·»åŠ ç›¸åŒçš„è¼¸å…¥
            last_user_input = None
            if self.conversation_history:
                for entry in reversed(self.conversation_history):
                    if entry.startswith("è­·ç†äººå“¡: "):
                        last_user_input = entry[5:]  # ç§»é™¤ "è­·ç†äººå“¡: " å‰ç¶´
                        break
            
            is_duplicate_input = (last_user_input == user_input)
            
            # åªæœ‰ä¸æ˜¯é‡è¤‡è¼¸å…¥æ™‚æ‰è¨˜éŒ„åˆ°å°è©±æ­·å²
            if not is_duplicate_input:
                self.conversation_history.append(f"è­·ç†äººå“¡: {user_input}")
                self.logger.info(f"âœ… æ–°è¼¸å…¥å·²è¨˜éŒ„åˆ°å°è©±æ­·å²")
            else:
                self.logger.info(f"âš ï¸ æª¢æ¸¬åˆ°é‡è¤‡è¼¸å…¥ï¼Œè·³éè¨˜éŒ„åˆ°å°è©±æ­·å²ï¼Œé¿å…æ··äº‚")
            
            # ä½¿ç”¨å„ªåŒ–çš„çµ±ä¸€å°è©±æ¨¡çµ„ (åƒ…1æ¬¡ API èª¿ç”¨)
            prediction = self.dialogue_module(
                user_input=user_input,
                character_name=self.character.name,
                character_persona=self.character.persona,
                character_backstory=self.character.backstory,
                character_goal=self.character.goal,
                character_details=self._get_character_details(),
                conversation_history=self._format_conversation_history()
            )
            
            self.logger.info(f"å„ªåŒ–è™•ç†å®Œæˆ:")
            self.logger.info(f"  - API èª¿ç”¨æ¬¡æ•¸: 1 (åŸæœ¬éœ€è¦ 3æ¬¡)")
            self.logger.info(f"  - ç¯€çœé…é¡ä½¿ç”¨: 66.7%")
            self.logger.info(f"  - å›æ‡‰æ•¸é‡: {len(prediction.responses)}")
            self.logger.info(f"  - æƒ…å¢ƒåˆ†é¡: {prediction.context_classification}")
            
            # æ›´æ–°ç¯€çœçµ±è¨ˆ
            saved_calls = prediction.processing_info.get('api_calls_saved', 2)
            self.optimization_stats['api_calls_saved'] += saved_calls
            self.optimization_stats['estimated_quota_saved_percent'] = (
                (self.optimization_stats['api_calls_saved'] / 
                 (self.optimization_stats['total_conversations'] * 3)) * 100
                if self.optimization_stats['total_conversations'] > 0 else 0
            )
            
            # è™•ç†å›æ‡‰çµæœ
            response_data = self._process_optimized_prediction(prediction)
            
            # é—œéµä¿®å¾©ï¼šæª¢æŸ¥ä¸¦ä¿®å¾©é€€åŒ–å›æ‡‰
            response_data = self._apply_degradation_prevention(response_data, user_input)
            
            # ====== Phase 1.3: æœƒè©±ç‹€æ…‹è®ŠåŒ–è¿½è¹¤ ======
            round_number = len(self.conversation_history) // 2 + 1  # ä¼°ç®—è¼ªæ¬¡
            self._track_session_state_changes(user_input, response_data, round_number)
            
            # æ›´æ–°å°è©±ç‹€æ…‹
            self._update_dialogue_state(response_data)
            
            # è™•ç†çµ‚ç«¯æ©Ÿæ¨¡å¼æˆ– GUI æ¨¡å¼
            if self.use_terminal:
                return self._handle_terminal_mode(user_input, response_data)
            else:
                return self._handle_gui_mode(user_input, response_data, gui_selected_response)
                
        except Exception as e:
            self.logger.error(f"å„ªåŒ–ç‰ˆå°è©±è™•ç†å¤±æ•—: {e}")
            self.logger.error("UNIFIED_FAILED: OptimizedDialogueManagerDSPy.process_turn exception", exc_info=True)
            
            # å˜—è©¦å¾çˆ¶é¡ç²å–å›æ‡‰ï¼Œç„¶å¾Œæ‡‰ç”¨é€€åŒ–é˜²è­·
            try:
                fallback_result = await super().process_turn(user_input, gui_selected_response)
                
                # å¦‚æœçˆ¶é¡è¿”å› JSON å­—ä¸²ï¼Œè§£æå®ƒ
                if isinstance(fallback_result, str):
                    try:
                        fallback_data = json.loads(fallback_result)
                        # æ‡‰ç”¨é€€åŒ–é˜²è­·åˆ°çˆ¶é¡å›æ‡‰
                        protected_data = self._apply_degradation_prevention(fallback_data, user_input)
                        return json.dumps(protected_data, ensure_ascii=False)
                    except json.JSONDecodeError:
                        # ä¸æ˜¯ JSONï¼Œç›´æ¥è¿”å›
                        return fallback_result
                else:
                    # çˆ¶é¡è¿”å›å­—å…¸ï¼Œç›´æ¥æ‡‰ç”¨é˜²è­·
                    return self._apply_degradation_prevention(fallback_result, user_input)
                    
            except Exception as fallback_error:
                self.logger.error(f"çˆ¶é¡å›é€€ä¹Ÿå¤±æ•—: {fallback_error}")
                self.logger.error("FALLBACK_CHAIN_FAILED: super().process_turn exception", exc_info=True)
                # æœ€çµ‚é˜²è­·ï¼šç”Ÿæˆå®‰å…¨çš„æ¢å¾©å›æ‡‰
                return self._generate_emergency_response(user_input)
    
    def _get_character_details(self) -> str:
        """ç²å–è§’è‰²è©³ç´°è³‡è¨Šçš„å­—ä¸²è¡¨ç¤º
        - å„ªå…ˆä½¿ç”¨ Character.details å­—æ®µï¼ˆdictï¼‰
        - å…¼å®¹èˆŠè¨­è¨ˆï¼šè‹¥ details ç¼ºå¤±ï¼Œå˜—è©¦æ‹¼æ¥å·²å­˜åœ¨å±¬æ€§
        """
        try:
            if isinstance(self.character.details, dict) and self.character.details:
                return json.dumps(self.character.details, ensure_ascii=False)
        except Exception:
            pass

        details = {}
        # å›é€€ï¼šè‹¥ details ä¸å¯ç”¨ï¼Œçµ„è£å·²çŸ¥å±¬æ€§ï¼ˆé€šå¸¸ä¸æœƒé€²å…¥ï¼‰
        for attr in ['fixed_settings', 'floating_settings', 'age', 'gender', 'medical_condition']:
            if hasattr(self.character, attr):
                try:
                    val = getattr(self.character, attr)
                    if isinstance(val, dict):
                        details.update(val)
                    else:
                        details[attr] = val
                except Exception:
                    continue
        return json.dumps(details, ensure_ascii=False) if details else "{}"
    
    def _process_optimized_prediction(self, prediction) -> dict:
        """è™•ç†å„ªåŒ–ç‰ˆé æ¸¬çµæœ"""
        try:
            responses = getattr(prediction, 'responses', [])
            state = getattr(prediction, 'state', 'NORMAL')
            dialogue_context = getattr(prediction, 'dialogue_context', 'ä¸€èˆ¬å°è©±')
            context_classification = getattr(prediction, 'context_classification', 'daily_routine_examples')
            processing_info = getattr(prediction, 'processing_info', None)
            
            # ç¢ºä¿å›æ‡‰æ ¼å¼æ­£ç¢º
            if isinstance(responses, str):
                try:
                    responses = json.loads(responses)
                except json.JSONDecodeError:
                    responses = [responses]
            
            if not isinstance(responses, list):
                responses = [str(responses)]
            
            if not responses:
                responses = ["æˆ‘éœ€è¦ä¸€é»æ™‚é–“æ€è€ƒ..."]
            
            return {
                "responses": responses,
                "state": state,
                "dialogue_context": dialogue_context,
                "context_classification": context_classification,
                "processing_info": processing_info,
                "optimization_info": {
                    "api_calls_used": 1,
                    "api_calls_saved": 2,
                    "efficiency_improvement": "66.7%"
                }
            }
            
        except Exception as e:
            self.logger.error(f"å„ªåŒ–é æ¸¬çµæœè™•ç†å¤±æ•—: {e}")
            return {
                "responses": ["æŠ±æ­‰ï¼Œè™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤"],
                "state": "CONFUSED",
                "dialogue_context": "ç³»çµ±éŒ¯èª¤"
            }
    
    def _update_dialogue_state(self, response_data: dict):
        """æ›´æ–°å°è©±ç‹€æ…‹"""
        try:
            from ..state import DialogueState
            new_state = response_data.get("state", "NORMAL")
            self.current_state = DialogueState(new_state)
            
            dialogue_context = response_data.get("dialogue_context", "")
            if dialogue_context:
                print(f"å„ªåŒ– DSPy åˆ¤æ–·çš„å°è©±æƒ…å¢ƒ: {dialogue_context}")
                
        except ValueError as e:
            self.logger.warning(f"ç„¡æ•ˆç‹€æ…‹ï¼Œè¨­ç½®ç‚º CONFUSED: {e}")
            from ..state import DialogueState
            self.current_state = DialogueState.CONFUSED
    
    def _handle_terminal_mode(self, user_input: str, response_data: dict) -> str:
        """è™•ç†çµ‚ç«¯æ©Ÿæ¨¡å¼çš„äº’å‹•"""
        import keyboard
        
        responses = response_data["responses"]
        
        print(f"\n{self.character.name} çš„å›æ‡‰é¸é …ï¼ˆå„ªåŒ– DSPy ç”Ÿæˆï¼Œç¯€çœ 66.7% API èª¿ç”¨ï¼‰ï¼š")
        for i, response in enumerate(responses, 1):
            print(f"{i}. {response}")
        print("0. é€™äº›é¸é …éƒ½ä¸é©åˆï¼ˆè·³éï¼Œç›´æ¥é€²å…¥ä¸‹ä¸€è¼ªå°è©±ï¼‰")
        print("q. çµæŸå°è©±")
        print("s. é¡¯ç¤ºå„ªåŒ–çµ±è¨ˆ")
        print("\nè«‹æŒ‰æ•¸å­—éµ 0-5 é¸æ“‡é¸é …ï¼Œs æŸ¥çœ‹çµ±è¨ˆï¼Œæˆ–æŒ‰ q çµæŸå°è©±...")
        
        while True:
            event = keyboard.read_event(suppress=True)
            if event.event_type == 'down':
                if event.name == '0':
                    print("\nè·³éæ­¤è¼ªå›æ‡‰ï¼Œè«‹ç¹¼çºŒå°è©±")
                    self.conversation_history.append("(è·³éæ­¤è¼ªå›æ‡‰)")
                    self.log_interaction(user_input, responses, selected_response="(è·³éæ­¤è¼ªå›æ‡‰)")
                    self.save_interaction_log()
                    return ""
                elif event.name == 'q':
                    print("\nçµæŸå°è©±")
                    print(self._get_optimization_summary())
                    self.save_interaction_log()
                    return "quit"
                elif event.name == 's':
                    print("\n" + self._get_optimization_summary())
                    continue
                elif event.name in ['1', '2', '3', '4', '5']:
                    choice = int(event.name)
                    if choice <= len(responses):
                        selected_response = responses[choice - 1]
                        print(f"\nå·²é¸æ“‡é¸é … {choice}: {selected_response}")
                        self.conversation_history.append(f"{self.character.name}: {selected_response}")
                        self.log_interaction(user_input, responses, selected_response=selected_response)
                        self.save_interaction_log()
                        return selected_response
    
    def _handle_gui_mode(self, user_input: str, response_data: dict, gui_selected_response: Optional[str] = None) -> str:
        """è™•ç† GUI æ¨¡å¼çš„äº’å‹•"""
        # è¨˜éŒ„äº’å‹•
        self.log_interaction(user_input, response_data["responses"], selected_response=gui_selected_response)
        self.save_interaction_log()
        
        # è¿½åŠ ç—…æ‚£å›æ‡‰åˆ°å°è©±æ­·å²ï¼ˆé¸æ“‡é¦–å€‹å»ºè­°ï¼Œä¾¿æ–¼ä¸‹ä¸€è¼ªæä¾›ä¸Šä¸‹æ–‡ï¼‰
        try:
            if response_data.get("responses"):
                top_resp = str(response_data["responses"][0])
                self.conversation_history.append(f"{self.character.name}: {top_resp}")
        except Exception:
            pass
        
        # è¿”å› JSON æ ¼å¼å›æ‡‰
        return json.dumps(response_data, ensure_ascii=False)
    
    def get_optimization_statistics(self) -> dict:
        """ç²å–å„ªåŒ–çµ±è¨ˆè³‡è¨Š"""
        base_stats = {}
        if hasattr(self, 'dialogue_module') and hasattr(self.dialogue_module, 'get_unified_statistics'):
            base_stats = self.dialogue_module.get_unified_statistics()
        
        return {
            **base_stats,
            **self.optimization_stats,
            'optimization_enabled': self.optimization_enabled,
            'efficiency_summary': {
                'conversations_processed': self.optimization_stats['total_conversations'],
                'total_api_calls_saved': self.optimization_stats['api_calls_saved'],
                'quota_savings_percent': f"{self.optimization_stats['estimated_quota_saved_percent']:.1f}%",
                'calls_per_conversation': '1 (åŸæœ¬ 3æ¬¡)',
                'optimization_factor': '3x æ•ˆç‡æå‡'
            }
        }
    
    def _get_optimization_summary(self) -> str:
        """ç²å–å„ªåŒ–æ‘˜è¦å­—ä¸²"""
        stats = self.get_optimization_statistics()
        return f"""
ğŸ¯ API èª¿ç”¨å„ªåŒ–çµ±è¨ˆæ‘˜è¦:
  - è™•ç†å°è©±æ•¸é‡: {stats['conversations_processed']}
  - ç¯€çœ API èª¿ç”¨: {stats['total_api_calls_saved']} æ¬¡
  - é…é¡ç¯€çœç‡: {stats['quota_savings_percent']}
  - æ•ˆç‡æå‡: æ¯æ¬¡å°è©±å¾ 3æ¬¡èª¿ç”¨ â†’ 1æ¬¡èª¿ç”¨
  - æ•´é«”æ•ˆç‡: æå‡ 3å€ï¼Œè§£æ±ºé…é¡é™åˆ¶å•é¡Œ
"""
    
    def _apply_degradation_prevention(self, response_data: dict, user_input: str) -> dict:
        """æ‡‰ç”¨é€€åŒ–é˜²è­·æªæ–½ï¼Œæª¢æ¸¬ä¸¦ä¿®å¾©å•é¡Œå›æ‡‰"""
        try:
            self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Checking response data")
            responses = response_data.get("responses", [])
            self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Found {len(responses)} responses")
            
            if not responses:
                self.logger.info(f"ğŸ” DEGRADATION PREVENTION: No responses, returning original")
                return response_data
            
            # æª¢æ¸¬é€€åŒ–æ¨¡å¼
            has_degradation = False
            degradation_indicators = []
            
            for i, response in enumerate(responses):
                response_str = str(response)
                self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Checking response {i+1}: '{response_str[:50]}...'")
                
                # æª¢æ¸¬è‡ªæˆ‘ä»‹ç´¹æ¨¡å¼
                if any(pattern in response_str for pattern in ["æˆ‘æ˜¯Patient", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯", "æˆ‘æ˜¯ç—…æ‚£"]):
                    has_degradation = True
                    degradation_indicators.append("self_introduction")
                    self.logger.warning(f"ğŸš¨ DETECTED: Self-introduction pattern in response {i+1}")
                
                # æª¢æ¸¬é€šç”¨å›æ‡‰æ¨¡å¼èˆ‡éŒ¯èª¤æ¨¡æ¿
                if any(pattern in response_str for pattern in ["æˆ‘å¯èƒ½æ²’æœ‰å®Œå…¨ç†è§£", "èƒ½è«‹æ‚¨æ›å€‹æ–¹å¼èªªæ˜", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©å—", "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨ç„¡æ³•æ­£ç¢ºå›æ‡‰"]):
                    has_degradation = True
                    degradation_indicators.append("generic_responses")
                    self.logger.warning(f"ğŸš¨ DETECTED: Generic response pattern in response {i+1}")

            # è‹¥ç‹€æ…‹ç‚º CONFUSEDï¼Œä¹Ÿè¦–ç‚ºé€€åŒ–ä¸¦é€²è¡Œä¿®å¾©
            if response_data.get("state") == "CONFUSED":
                has_degradation = True
                if "confused_state" not in degradation_indicators:
                    degradation_indicators.append("confused_state")
            
            if has_degradation:
                self.logger.warning(f"ğŸš¨ DEGRADATION PREVENTION: æª¢æ¸¬åˆ°é€€åŒ–æ¨¡å¼ {degradation_indicators}ï¼Œå•Ÿå‹•ä¿®å¾©æ©Ÿåˆ¶")
                
                # ç”Ÿæˆä¿®å¾©å¾Œçš„å›æ‡‰
                fixed_responses = self._generate_recovery_responses(user_input)
                
                response_data["responses"] = fixed_responses
                response_data["state"] = "NORMAL"
                response_data["dialogue_context"] = "å·²ä¿®å¾©çš„é†«ç™‚å°è©±"
                response_data["recovery_applied"] = True
                response_data["original_degradation"] = degradation_indicators
                
                # è§¸ç™¼ä¸Šä¸‹æ–‡é‡ç½®ä»¥é˜²æ­¢å¾ŒçºŒé€€åŒ–
                self._trigger_context_reset()
                
                self.logger.info(f"âœ… DEGRADATION PREVENTION: é€€åŒ–ä¿®å¾©å®Œæˆï¼Œç”Ÿæˆ {len(fixed_responses)} å€‹ä¿®å¾©å›æ‡‰")
            else:
                self.logger.info(f"âœ… DEGRADATION PREVENTION: No degradation detected, keeping original responses")
            
            return response_data
            
        except Exception as e:
            self.logger.error(f"ğŸš¨ DEGRADATION PREVENTION: é€€åŒ–é˜²è­·å¤±æ•—: {e}")
            import traceback
            self.logger.error(f"ğŸš¨ DEGRADATION PREVENTION: Traceback: {traceback.format_exc()}")
            return response_data
    
    def _generate_recovery_responses(self, user_input: str) -> list:
        """ç”Ÿæˆæ¢å¾©æ€§å›æ‡‰ï¼ŒåŸºæ–¼è§’è‰²è¨­å®šå’Œè¼¸å…¥å…§å®¹"""
        # åŸºæ–¼ç”¨æˆ¶è¼¸å…¥ç”Ÿæˆé©åˆçš„ç—…æ‚£å›æ‡‰
        input_lower = user_input.lower()
        
        if "æ„Ÿè¦º" in user_input or "æ€éº¼æ¨£" in user_input:
            return [
                "é‚„å¯ä»¥ï¼Œå‚·å£æœ‰é»ç·Šç¹ƒã€‚",
                "æ¢å¾©å¾—é‚„ä¸éŒ¯ï¼Œå°±æ˜¯æœ‰é»ç´¯ã€‚",
                "é‚„è¡Œï¼Œä½†æœ‰æ™‚æœƒè¦ºå¾—ä¸å¤ªèˆ’æœã€‚",
                "ç›®å‰ç‹€æ³é‚„ç©©å®šã€‚",
                "æ„Ÿè¦ºæ¯”æ˜¨å¤©å¥½ä¸€äº›äº†ã€‚"
            ]
        elif "ç™¼ç‡’" in user_input or "ä¸èˆ’æœ" in user_input:
            return [
                "ç›®å‰æ²’æœ‰ç™¼ç‡’ï¼Œä½†å‚·å£å‘¨åœæœ‰é»è…«è„¹ã€‚",
                "æ²’æœ‰ç™¼ç‡’ï¼Œä½†å¶çˆ¾æœƒè¦ºå¾—æœ‰é»ç—›ã€‚",
                "é«”æº«æ­£å¸¸ï¼Œå°±æ˜¯æœ‰äº›ç–²å‹ã€‚",
                "æ²’æœ‰æ˜é¡¯ç™¼ç‡’ç—‡ç‹€ã€‚",
                "ç›®å‰æ²’æœ‰ç™¼ç‡’ï¼Œä½†ä¼‘æ¯ä¸å¤ªå¥½ã€‚"
            ]
        elif "ç—‡ç‹€" in user_input:
            return [
                "ä¸»è¦å°±æ˜¯å‚·å£æœ‰é»ç·Šç¹ƒæ„Ÿã€‚",
                "å¶çˆ¾æœƒè¦ºå¾—æœ‰é»ç–¼ç—›ï¼Œå…¶ä»–é‚„å¥½ã€‚",
                "å°±æ˜¯åƒæ±è¥¿æ™‚æœ‰é»å›°é›£ã€‚",
                "æ²’æœ‰å…¶ä»–ç‰¹åˆ¥ä¸èˆ’æœçš„åœ°æ–¹ã€‚",
                "é™¤äº†å‚·å£ï¼Œå…¶ä»–éƒ½é‚„æ­£å¸¸ã€‚"
            ]
        elif "æª¢æŸ¥" in user_input:
            return [
                "å¥½ï¼Œéƒ½è½ä½ å€‘çš„å®‰æ’ã€‚",
                "å¯ä»¥ï¼Œæª¢æŸ¥æ˜¯å¿…è¦çš„ã€‚",
                "æ²’å•é¡Œï¼Œä»€éº¼æ™‚å€™æª¢æŸ¥ï¼Ÿ",
                "å¥½çš„ï¼Œæˆ‘æœƒé…åˆã€‚",
                "éœ€è¦åšä»€éº¼æº–å‚™å—ï¼Ÿ"
            ]
        else:
            # é€šç”¨æ¢å¾©å›æ‡‰
            return [
                "å¥½çš„ï¼Œæˆ‘çŸ¥é“äº†ã€‚",
                "å—¯ï¼Œè½èµ·ä¾†åˆç†ã€‚",
                "æˆ‘æœƒé…åˆæ²»ç™‚çš„ã€‚",
                "è¬è¬ä½ çš„é—œå¿ƒã€‚",
                "é‚£å°±éº»ç…©ä½ å€‘äº†ã€‚"
            ]
    
    def _trigger_context_reset(self):
        """è§¸ç™¼ä¸Šä¸‹æ–‡é‡ç½®ï¼Œé˜²æ­¢å¾ŒçºŒé€€åŒ–"""
        try:
            # æ¸…ç†å°è©±æ­·å²ï¼Œä¿ç•™æœ€è¿‘çš„é—œéµä¿¡æ¯
            if len(self.conversation_history) > 4:
                # åªä¿ç•™æœ€è¿‘2è¼ªå°è©±
                recent_history = self.conversation_history[-4:]
                self.conversation_history = recent_history
                self.logger.info(f"ğŸ”„ åŸ·è¡Œä¸Šä¸‹æ–‡é‡ç½®ï¼Œä¿ç•™æœ€è¿‘ {len(recent_history)} æ¢è¨˜éŒ„")
            
            # é‡ç½® DSPy æ¨¡çµ„å…§éƒ¨ç‹€æ…‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            if hasattr(self.dialogue_module, 'reset_context'):
                self.dialogue_module.reset_context()
                
        except Exception as e:
            self.logger.error(f"ä¸Šä¸‹æ–‡é‡ç½®å¤±æ•—: {e}")
    
    def _track_session_state_changes(self, user_input: str, response_data: dict, round_number: int):
        """è¿½è¹¤æœƒè©±ç‹€æ…‹è®ŠåŒ–å’Œé€€åŒ–æŒ‡æ¨™
        
        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥
            response_data: å›æ‡‰è³‡æ–™
            round_number: å°è©±è¼ªæ¬¡
        """
        try:
            self.logger.info(f"=== SESSION STATE TRACKING - Round {round_number} ===")
            
            # åŸºæœ¬æœƒè©±è³‡è¨Š
            self.logger.info(f"ğŸ”¢ CONVERSATION METRICS:")
            self.logger.info(f"  ğŸ“Š Round Number: {round_number}")
            self.logger.info(f"  ğŸ“ˆ Total Conversation History: {len(self.conversation_history)} entries")
            self.logger.info(f"  ğŸ“ Current Input Length: {len(user_input)} chars")
            
            # æœƒè©±ç‹€æ…‹åˆ†æ
            session_state = self._analyze_session_state(response_data, round_number)
            self.logger.info(f"  ğŸ­ Session State Analysis:")
            for key, value in session_state.items():
                self.logger.info(f"    {key}: {value}")
            
            # è§’è‰²ä¸€è‡´æ€§è¿½è¹¤
            consistency_score = self._calculate_consistency_score(response_data)
            self.logger.info(f"  ğŸ¯ Character Consistency Score: {consistency_score:.3f}")
            
            # å›æ‡‰å“è³ªæŒ‡æ¨™
            quality_metrics = self._calculate_response_quality_metrics(response_data)
            self.logger.info(f"  ğŸ† Response Quality Metrics:")
            for metric, value in quality_metrics.items():
                self.logger.info(f"    {metric}: {value}")
            
            # é€€åŒ–é¢¨éšªè©•ä¼°
            degradation_risk = self._assess_degradation_risk(response_data, round_number)
            self.logger.info(f"  âš ï¸  Degradation Risk: {degradation_risk['risk_level']} ({degradation_risk['score']:.2f})")
            
            # æœƒè©±è¤‡é›œåº¦åˆ†æ
            complexity_analysis = self._analyze_conversation_complexity()
            self.logger.info(f"  ğŸ§® Conversation Complexity:")
            for key, value in complexity_analysis.items():
                self.logger.info(f"    {key}: {value}")
            
            # è¨˜æ†¶ä½¿ç”¨æƒ…æ³
            memory_info = self._track_memory_usage()
            self.logger.info(f"  ğŸ’¾ Memory Usage: {memory_info}")
            
            # å¦‚æœæ˜¯é—œéµè¼ªæ¬¡ï¼ˆ3-5è¼ªï¼‰ï¼Œé¡å¤–è¨˜éŒ„
            if 3 <= round_number <= 5:
                self.logger.warning(f"ğŸš¨ CRITICAL ROUND {round_number} - Enhanced monitoring active")
                self._log_critical_round_analysis(user_input, response_data, round_number)
            
            # å„²å­˜ç‹€æ…‹æ­·å²ï¼ˆç”¨æ–¼è¶¨å‹¢åˆ†æï¼‰
            self._store_session_state_history(session_state, round_number)
            
        except Exception as e:
            self.logger.error(f"æœƒè©±ç‹€æ…‹è¿½è¹¤å¤±æ•—: {e}")
    
    def _analyze_session_state(self, response_data: dict, round_number: int) -> dict:
        """åˆ†æç•¶å‰æœƒè©±ç‹€æ…‹"""
        try:
            responses = response_data.get("responses", [])
            state = response_data.get("state", "UNKNOWN")
            context = response_data.get("dialogue_context", "UNKNOWN")
            
            return {
                "Response_Count": len(responses),
                "Dialogue_State": state,
                "Dialogue_Context": context,
                "Round_Number": round_number,
                "Has_Recovery_Applied": response_data.get("recovery_applied", False),
                "Original_Degradation": response_data.get("original_degradation", []),
                "Emergency_Recovery": response_data.get("emergency_recovery", False)
            }
        except Exception as e:
            return {"Error": str(e)}
    
    def _calculate_consistency_score(self, response_data: dict) -> float:
        """è¨ˆç®—è§’è‰²ä¸€è‡´æ€§åˆ†æ•¸"""
        try:
            responses = response_data.get("responses", [])
            if not responses:
                return 0.0
            
            score = 1.0
            
            # æª¢æŸ¥è‡ªæˆ‘ä»‹ç´¹æ¨¡å¼ï¼ˆåš´é‡æ‰£åˆ†ï¼‰
            for response in responses:
                if any(pattern in str(response) for pattern in ["æˆ‘æ˜¯Patient", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯"]):
                    score -= 0.4
                    break
            
            # æª¢æŸ¥é€šç”¨å›æ‡‰ï¼ˆä¸­åº¦æ‰£åˆ†ï¼‰
            for response in responses:
                if any(pattern in str(response) for pattern in ["æ²’æœ‰å®Œå…¨ç†è§£", "æ›å€‹æ–¹å¼èªªæ˜", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©"]):
                    score -= 0.2
                    break
            
            # æª¢æŸ¥é†«ç™‚ç›¸é—œæ€§ï¼ˆåŠ åˆ†ï¼‰
            medical_terms = ["ç—‡ç‹€", "æª¢æŸ¥", "å‚·å£", "æ¢å¾©", "æ²»ç™‚", "è—¥ç‰©", "è­·ç†"]
            has_medical_context = any(
                any(term in str(response) for term in medical_terms)
                for response in responses
            )
            if has_medical_context:
                score += 0.1
            
            return max(0.0, min(1.0, score))
            
        except Exception:
            return 0.5
    
    def _calculate_response_quality_metrics(self, response_data: dict) -> dict:
        """è¨ˆç®—å›æ‡‰å“è³ªæŒ‡æ¨™"""
        try:
            responses = response_data.get("responses", [])
            
            metrics = {
                "Response_Count": len(responses),
                "Average_Length": sum(len(str(r)) for r in responses) // max(1, len(responses)),
                "Has_Medical_Terms": self._has_medical_terms(responses),
                "Has_Self_Introduction": self._has_self_introduction(response_data),
                "Context_Relevance": self._calculate_context_relevance("", response_data),  # ç°¡åŒ–ç‰ˆ
                "Diversity_Score": self._calculate_response_diversity(responses)
            }
            
            return metrics
            
        except Exception as e:
            return {"Error": str(e)}
    
    def _has_medical_terms(self, responses: list) -> bool:
        """æª¢æŸ¥æ˜¯å¦åŒ…å«é†«ç™‚è¡“èª"""
        medical_terms = ["ç—‡ç‹€", "æª¢æŸ¥", "å‚·å£", "æ¢å¾©", "æ²»ç™‚", "è—¥ç‰©", "è­·ç†", "é†«å¸«", "ç—…æˆ¿"]
        return any(
            any(term in str(response) for term in medical_terms)
            for response in responses
        )
    
    def _calculate_response_diversity(self, responses: list) -> float:
        """è¨ˆç®—å›æ‡‰å¤šæ¨£æ€§åˆ†æ•¸"""
        try:
            if len(responses) <= 1:
                return 0.0
            
            # ç°¡å–®çš„å¤šæ¨£æ€§æª¢æŸ¥ï¼šè¨ˆç®—ä¸åŒé–‹é ­çš„æ¯”ä¾‹
            first_chars = [str(r)[0] if str(r) else '' for r in responses]
            unique_starts = len(set(first_chars))
            
            return unique_starts / len(responses)
            
        except Exception:
            return 0.5
    
    def _assess_degradation_risk(self, response_data: dict, round_number: int) -> dict:
        """è©•ä¼°é€€åŒ–é¢¨éšª"""
        try:
            risk_score = 0.0
            risk_factors = []
            
            # è¼ªæ¬¡é¢¨éšªï¼ˆç¬¬4-5è¼ªé¢¨éšªè¼ƒé«˜ï¼‰
            if 4 <= round_number <= 5:
                risk_score += 0.3
                risk_factors.append("Critical_Round")
            
            # å›æ‡‰å“è³ªé¢¨éšª
            responses = response_data.get("responses", [])
            if len(responses) < 3:
                risk_score += 0.2
                risk_factors.append("Few_Responses")
            
            # è‡ªæˆ‘ä»‹ç´¹é¢¨éšª
            if self._has_self_introduction(response_data):
                risk_score += 0.4
                risk_factors.append("Self_Introduction")
            
            # ç‹€æ…‹é¢¨éšª
            if response_data.get("state") == "CONFUSED":
                risk_score += 0.1
                risk_factors.append("Confused_State")
            
            # å·²æ‡‰ç”¨æ¢å¾©çš„é¢¨éšª
            if response_data.get("recovery_applied"):
                risk_score += 0.2
                risk_factors.append("Recovery_Applied")
            
            # ç¢ºå®šé¢¨éšªç­‰ç´š
            if risk_score >= 0.7:
                risk_level = "HIGH"
            elif risk_score >= 0.4:
                risk_level = "MEDIUM"
            elif risk_score >= 0.2:
                risk_level = "LOW"
            else:
                risk_level = "MINIMAL"
            
            return {
                "score": risk_score,
                "risk_level": risk_level,
                "factors": risk_factors
            }
            
        except Exception as e:
            return {"score": 1.0, "risk_level": "ERROR", "factors": [str(e)]}
    
    def _analyze_conversation_complexity(self) -> dict:
        """åˆ†æå°è©±è¤‡é›œåº¦"""
        try:
            history_length = len(self.conversation_history)
            total_chars = sum(len(entry) for entry in self.conversation_history)
            
            return {
                "History_Entries": history_length,
                "Total_Characters": total_chars,
                "Average_Entry_Length": total_chars // max(1, history_length),
                "Estimated_Rounds": history_length // 2,
                "Complexity_Level": (
                    "High" if total_chars > 2000 else
                    "Medium" if total_chars > 1000 else
                    "Low"
                )
            }
        except Exception:
            return {"Error": "Analysis failed"}
    
    def _track_memory_usage(self) -> str:
        """è¿½è¹¤è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
        try:
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            return f"{memory_mb:.1f} MB"
        except ImportError:
            return "N/A (psutil not available)"
        except Exception:
            return "Error"
    
    def _log_critical_round_analysis(self, user_input: str, response_data: dict, round_number: int):
        """è¨˜éŒ„é—œéµè¼ªæ¬¡çš„è©³ç´°åˆ†æ"""
        self.logger.warning(f"ğŸ” CRITICAL ROUND {round_number} DETAILED ANALYSIS:")
        self.logger.warning(f"  ğŸ“¥ Input: '{user_input}'")
        self.logger.warning(f"  ğŸ“Š Response State: {response_data.get('state', 'UNKNOWN')}")
        self.logger.warning(f"  ğŸŒ Context: {response_data.get('dialogue_context', 'UNKNOWN')}")
        self.logger.warning(f"  ğŸ’¬ Response Count: {len(response_data.get('responses', []))}")
        
        # è©³ç´°å›æ‡‰åˆ†æ
        responses = response_data.get('responses', [])
        for i, response in enumerate(responses, 1):
            has_issues = any(pattern in str(response) for pattern in ["æˆ‘æ˜¯Patient", "æ²’æœ‰å®Œå…¨ç†è§£", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©"])
            status = "ğŸ”´ PROBLEMATIC" if has_issues else "âœ… OK"
            self.logger.warning(f"    Response {i}: {status} - '{str(response)[:100]}...'")
    
    def _store_session_state_history(self, session_state: dict, round_number: int):
        """å„²å­˜æœƒè©±ç‹€æ…‹æ­·å²"""
        try:
            if not hasattr(self, '_session_history'):
                self._session_history = []
            
            history_entry = {
                "round": round_number,
                "timestamp": time.time(),
                "state": session_state
            }
            
            self._session_history.append(history_entry)
            
            # åªä¿ç•™æœ€è¿‘10è¼ªçš„è¨˜éŒ„
            if len(self._session_history) > 10:
                self._session_history = self._session_history[-10:]
                
        except Exception as e:
            self.logger.error(f"ç‹€æ…‹æ­·å²å„²å­˜å¤±æ•—: {e}")
    
    def _generate_emergency_response(self, user_input: str) -> str:
        """ç”Ÿæˆç·Šæ€¥æ¢å¾©å›æ‡‰ï¼Œç•¶æ‰€æœ‰å…¶ä»–æ–¹æ³•éƒ½å¤±æ•—æ™‚ä½¿ç”¨"""
        self.logger.warning(f"ğŸš¨ ç”Ÿæˆç·Šæ€¥æ¢å¾©å›æ‡‰ for: {user_input}")
        
        # æ ¹æ“šè¼¸å…¥ç”ŸæˆåŸºæœ¬çš„ç—…æ‚£å›æ‡‰
        emergency_responses = self._generate_recovery_responses(user_input)
        
        emergency_data = {
            "status": "success",
            "responses": emergency_responses,
            "state": "NORMAL", 
            "dialogue_context": "ç·Šæ€¥æ¢å¾©æ¨¡å¼",
            "session_id": getattr(self, 'current_session_id', None),
            "emergency_recovery": True,
            "speech_recognition_options": None,
            "original_transcription": None
        }
        
        return json.dumps(emergency_data, ensure_ascii=False)

    def cleanup(self):
        """æ¸…ç†è³‡æº"""
        self.logger.info("æ¸…ç†å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨")
        
        # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
        final_stats = self.get_optimization_statistics()
        self.logger.info(f"æœ€çµ‚å„ªåŒ–çµ±è¨ˆ: {final_stats}")
        
        if hasattr(self, 'dialogue_module') and hasattr(self.dialogue_module, 'cleanup'):
            self.dialogue_module.cleanup()


# æ¸¬è©¦å‡½æ•¸
def test_optimized_dialogue_manager():
    """æ¸¬è©¦å„ªåŒ–ç‰ˆå°è©±ç®¡ç†å™¨"""
    print("ğŸ§ª æ¸¬è©¦å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨...")
    
    try:
        # å‰µå»ºæ¸¬è©¦è§’è‰²
        from ..character import Character
        test_character = Character(
            name="æ¸¬è©¦ç—…æ‚£",
            persona="å‹å–„ä½†æ“”å¿ƒçš„ç—…æ‚£",
            backstory="ä½é™¢ä¸­é€²è¡Œåº·å¾©æ²»ç™‚",
            goal="ç›¡å¿«åº·å¾©å‡ºé™¢"
        )
        
        # å‰µå»ºå„ªåŒ–ç‰ˆç®¡ç†å™¨
        manager = OptimizedDialogueManagerDSPy(test_character)
        
        print("âœ… å„ªåŒ–ç‰ˆå°è©±ç®¡ç†å™¨å‰µå»ºæˆåŠŸ")
        print(manager._get_optimization_summary())
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_optimized_dialogue_manager()

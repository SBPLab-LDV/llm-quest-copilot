#!/usr/bin/env python3
"""
å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨

ä½¿ç”¨çµ±ä¸€å°è©±æ¨¡çµ„ï¼Œå°‡ API èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ï¼Œ
è§£æ±º Gemini API é…é¡é™åˆ¶å•é¡Œã€‚
"""

import json
import logging
import re
import time
from typing import Any, Dict, List, Optional, Union

from ..dialogue import DialogueManager
from ..character import Character
from .unified_dialogue_module import UnifiedDSPyDialogueModule
from .sensitive_question_module import SensitiveQuestionRewriteModule
from .config import get_config

logger = logging.getLogger(__name__)


class OptimizedDialogueManagerDSPy(DialogueManager):
    """å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨

    ä¸»è¦å„ªåŒ–ï¼š
    - API èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ (ç¯€çœ 66.7% é…é¡ä½¿ç”¨)
    - ä¿æŒå®Œå…¨çš„ API å…¼å®¹æ€§
    - æä¾›è©³ç´°çš„ç¯€çœçµ±è¨ˆ
    """
    
    def __init__(self, character: Character, use_terminal: bool = False, log_dir: str = "logs", log_file_basename: Optional[str] = None):
        """åˆå§‹åŒ–å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨
        
        Args:
            character: Character instance containing the NPC's information (as patient identifier)
            use_terminal: Whether to use terminal mode for interaction
            log_dir: Directory to save interaction logs
        """
        # åˆå§‹åŒ–çˆ¶é¡
        super().__init__(character, use_terminal, log_dir, log_file_basename=log_file_basename)
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("OptimizedDialogueManagerDSPy.__init__ - ä½¿ç”¨çµ±ä¸€å°è©±æ¨¡çµ„")
        
        # è®€å–æ•æ„Ÿæå•æ”¹å¯«é–‹é—œ
        dspy_config = get_config().get_dspy_config()
        self.enable_sensitive_rewrite = dspy_config.get('enable_sensitive_rewrite', True)

        # åˆå§‹åŒ–å„ªåŒ–çš„ DSPy çµ„ä»¶ï¼ˆfail-fastï¼šä¸å…è¨±å›é€€åˆ°å…¶ä»–å¯¦ç¾ï¼‰
        self.dialogue_module = UnifiedDSPyDialogueModule()
        self.optimization_enabled = True
        self.logger.info("å„ªåŒ–çµ±ä¸€å°è©±æ¨¡çµ„åˆå§‹åŒ–æˆåŠŸ - API èª¿ç”¨ç¯€çœ 66.7%")
        if self.enable_sensitive_rewrite:
            self.sensitive_question_module = SensitiveQuestionRewriteModule()
        else:
            self.sensitive_question_module = None
            self.logger.info("æ•æ„Ÿæå•æ”¹å¯«å·²åœç”¨ï¼ˆenable_sensitive_rewrite=Falseï¼‰")
        
        # çµ±è¨ˆè¿½è¹¤
        self.optimization_stats = {
            'total_conversations': 0,
            'api_calls_saved': 0,
            'estimated_quota_saved_percent': 0.0
        }
        self._character_profile_emitted = False
        self._last_turn_timings: Optional[Dict] = None

    async def process_turn(self, user_input: str, gui_selected_response: Optional[str] = None) -> Union[str, dict]:
        """è™•ç†å„ªåŒ–ç‰ˆå°è©±è¼ªæ¬¡
        
        Args:
            user_input: The user's input text
            gui_selected_response: Selected response in GUI mode (optional)
            
        Returns:
            Either a string response (terminal mode) or JSON response (GUI mode)
        """
        if not self.optimization_enabled:
            raise RuntimeError("OptimizedDialogueManagerDSPy is disabled (fail-fast; no fallback).")
        
        self.optimization_stats['total_conversations'] += 1
        
        try:
            self.logger.info(f"=== å„ªåŒ–ç‰ˆå°è©±è™•ç† (ç¬¬ {self.optimization_stats['total_conversations']} æ¬¡) ===")
            self.logger.info(f"ç”¨æˆ¶è¼¸å…¥: {user_input}")

            # Echo suppression: avoid recording caregiver line if it exactly repeats last patient utterance
            try:
                normalized_input = (user_input or "").strip()
                last_patient_utterance: Optional[str] = None
                if self.conversation_history and normalized_input:
                    patient_prefix = f"{self.character.name}: "
                    for entry in reversed(self.conversation_history):
                        if isinstance(entry, str):
                            s = entry.strip()
                            if s.startswith(patient_prefix):
                                last_patient_utterance = s[len(patient_prefix):].strip()
                                break
                is_echo_of_patient = last_patient_utterance and (last_patient_utterance == normalized_input)
            except Exception:
                is_echo_of_patient = False
            
            # æª¢æŸ¥é‡è¤‡è¼¸å…¥ - é¿å…åœ¨æœƒè©±ä¸­æ·»åŠ ç›¸åŒçš„è¼¸å…¥
            last_user_input = None
            if self.conversation_history:
                for entry in reversed(self.conversation_history):
                    if entry.startswith("å°è©±æ–¹: "):
                        last_user_input = entry[4:]  # ç§»é™¤ "å°è©±æ–¹: " å‰ç¶´
                        break
            
            is_duplicate_input = (last_user_input == user_input)
            
            # åªæœ‰ä¸æ˜¯é‡è¤‡è¼¸å…¥æ™‚æ‰è¨˜éŒ„åˆ°å°è©±æ­·å²
            if not is_duplicate_input and not is_echo_of_patient:
                self.conversation_history.append(f"å°è©±æ–¹: {user_input}")
                self.logger.info(f"âœ… æ–°è¼¸å…¥å·²è¨˜éŒ„åˆ°å°è©±æ­·å²")
            else:
                reason = "èˆ‡ä¸Šä¸€è¼ªå°è©±æ–¹è¼¸å…¥é‡è¤‡" if is_duplicate_input else "èˆ‡ä¸Šä¸€è¼ªç—…æ‚£é¸æ“‡å›è¦†ç›¸åŒ(å›è²æŠ‘åˆ¶)"
                self.logger.info(f"âš ï¸ è·³éè¨˜éŒ„åˆ°å°è©±æ­·å²ï¼š{reason}")
            
            # ä½¿ç”¨å„ªåŒ–çš„çµ±ä¸€å°è©±æ¨¡çµ„ (åƒ…1æ¬¡ API èª¿ç”¨)
            _t_turn_start = time.time()
            self._last_turn_timings = None

            _t_dialogue_module_start = time.time()
            prediction = self.dialogue_module(
                user_input=user_input,
                character_name=self.character.name,
                character_persona=self.character.persona,
                character_backstory=self.character.backstory,
                character_goal=self.character.goal,
                character_details=self._get_character_details(),
                conversation_history=self._format_conversation_history()
            )
            _t_dialogue_module_end = time.time()

            self.logger.info(f"å„ªåŒ–è™•ç†å®Œæˆ:")
            self.logger.info(f"  - API èª¿ç”¨æ¬¡æ•¸: 1 (åŸæœ¬éœ€è¦ 3æ¬¡)")
            self.logger.info(f"  - ç¯€çœé…é¡ä½¿ç”¨: 66.7%")
            self.logger.info(f"  - å›æ‡‰æ•¸é‡: {len(prediction.responses)}")
            self.logger.info(f"  - æƒ…å¢ƒåˆ†é¡: {getattr(prediction, 'context_classification', None)}")

            # æ›´æ–°ç¯€çœçµ±è¨ˆ
            saved_calls = prediction.processing_info.get('api_calls_saved', 2)
            self.optimization_stats['api_calls_saved'] += saved_calls
            self.optimization_stats['estimated_quota_saved_percent'] = (
                (self.optimization_stats['api_calls_saved'] /
                 (self.optimization_stats['total_conversations'] * 3)) * 100
                if self.optimization_stats['total_conversations'] > 0 else 0
            )

            # è®“ rewrite æ¨¡çµ„æ±ºç­–æ˜¯å¦éœ€è¦æ”¹å¯«ï¼ˆè‹¥åœç”¨ï¼Œç›´æ¥ä½¿ç”¨åŸºç¤é æ¸¬ï¼‰
            _t_sensitive_rewrite_start = time.time()
            rewrite_result = self._attempt_sensitive_rewrite(user_input, prediction)
            _t_sensitive_rewrite_end = time.time()
            _sensitive_rewrite_triggered = rewrite_result is not None

            _t_post_processing_start = time.time()
            response_data = rewrite_result if rewrite_result else self._process_optimized_prediction(prediction)

            # ====== Phase 1.3: æœƒè©±ç‹€æ…‹è®ŠåŒ–è¿½è¹¤ ======
            round_number = len(self.conversation_history) // 2 + 1  # ä¼°ç®—è¼ªæ¬¡
            self._track_session_state_changes(user_input, response_data, round_number)

            # æ›´æ–°å°è©±ç‹€æ…‹
            self._update_dialogue_state(response_data)

            # è™•ç†çµ‚ç«¯æ©Ÿæ¨¡å¼æˆ– GUI æ¨¡å¼
            if self.use_terminal:
                result = self._handle_terminal_mode(user_input, response_data)
            else:
                result = self._handle_gui_mode(user_input, response_data, gui_selected_response)
            _t_post_processing_end = time.time()

            _t_turn_end = time.time()
            self._last_turn_timings = {
                "total_s": round(_t_turn_end - _t_turn_start, 4),
                "dialogue_module_s": round(_t_dialogue_module_end - _t_dialogue_module_start, 4),
                "sensitive_rewrite_s": round(_t_sensitive_rewrite_end - _t_sensitive_rewrite_start, 4),
                "post_processing_s": round(_t_post_processing_end - _t_post_processing_start, 4),
                "sensitive_rewrite_triggered": _sensitive_rewrite_triggered,
            }
            self.logger.info("[Timing] process_turn: %s", self._last_turn_timings)

            return result
                
        except Exception as e:
            self.logger.error(f"å„ªåŒ–ç‰ˆå°è©±è™•ç†å¤±æ•—: {e}")
            self.logger.error("UNIFIED_FAILED: OptimizedDialogueManagerDSPy.process_turn exception", exc_info=True)
            
            # å˜—è©¦å¾çˆ¶é¡ç²å–å›æ‡‰ï¼Œç„¶å¾Œæ‡‰ç”¨é€€åŒ–é˜²è­·
            try:
                fallback_result = await super().process_turn(user_input, gui_selected_response)
                
                # å¦‚æœçˆ¶é¡è¿”å› JSON å­—ä¸²ï¼Œè§£æå®ƒ
                if isinstance(fallback_result, str):
                    try:
                        fallback_data = json.loads(fallback_result)
                        return json.dumps(fallback_data, ensure_ascii=False)
                    except json.JSONDecodeError:
                        # ä¸æ˜¯ JSONï¼Œç›´æ¥è¿”å›
                        return fallback_result
                else:
                    # çˆ¶é¡è¿”å›å­—å…¸ï¼Œç›´æ¥è¿”å›
                    return fallback_result
                    
            except Exception as fallback_error:
                self.logger.error(f"çˆ¶é¡å›é€€ä¹Ÿå¤±æ•—: {fallback_error}")
                self.logger.error("FALLBACK_CHAIN_FAILED: super().process_turn exception", exc_info=True)
                # æœ€çµ‚é˜²è­·ï¼šç”Ÿæˆå®‰å…¨çš„æ¢å¾©å›æ‡‰
                return self._generate_emergency_response(user_input)
    
    def _get_character_details(self) -> Any:
        """å›å‚³å®Œæ•´çš„è§’è‰²è©³ç´°è¨­å®šï¼ˆç›¡å¯èƒ½ä¿ç•™ characters.yaml çš„å…¨éƒ¨è³‡è¨Šï¼‰ã€‚

        - è‹¥æœ‰ details å­—å…¸ï¼šè¿”å› { fixed_settings, floating_settings, summary }
        - è‹¥ details ç‚ºå¯è§£æçš„ JSON å­—ä¸²ï¼šè§£æå¾Œè¿”å›åŒä¸Šçµæ§‹
        - å¦å‰‡ï¼šè¿”å›ç°¡çŸ­å­—ä¸²æ‘˜è¦ï¼ˆèˆ‡èˆŠè¡Œç‚ºç›¸å®¹ï¼‰
        """
        summary_parts: List[str] = []

        details_dict: Optional[Dict[str, Any]] = None
        try:
            if isinstance(self.character.details, dict) and self.character.details:
                details_dict = self.character.details
            elif isinstance(self.character.details, str) and self.character.details.strip():
                details_dict = json.loads(self.character.details)
        except Exception:
            details_dict = None

        if details_dict:
            fixed = details_dict.get('fixed_settings') or {}
            floating = details_dict.get('floating_settings') or {}

            name = fixed.get('å§“å') or getattr(self.character, 'name', '')
            diagnosis = fixed.get('è¨ºæ–·') or fixed.get('ç›®å‰è¨ºæ–·') or ''
            staging = fixed.get('åˆ†æœŸ') or fixed.get('è¨ºæ–·åˆ†æœŸ') or ''
            summary_parts.append(
                "å§“å: {name} / è¨ºæ–·: {diag}{stage}".format(
                    name=name or getattr(self.character, 'name', 'æœªçŸ¥'),
                    diag=diagnosis,
                    stage=f" ({staging})" if staging else ""
                ).strip()
            )

            treatment_stage = floating.get('ç›®å‰æ²»ç™‚éšæ®µ') or floating.get('æ²»ç™‚éšæ®µ') or ''
            treatment_status = floating.get('ç›®å‰æ²»ç™‚ç‹€æ…‹') or ''
            if treatment_stage or treatment_status:
                line = "ç›®å‰æ²»ç™‚éšæ®µ: {stage}".format(stage=treatment_stage or treatment_status)
                if treatment_stage and treatment_status and treatment_status != treatment_stage:
                    line += f"ï¼›ç‹€æ…‹: {treatment_status}"
                summary_parts.append(line)

            caregiver = floating.get('ä¸»è¦ç…§é¡§è€…') or floating.get('é™ªä¼´è€…')
            if caregiver:
                summary_parts.append(f"é™ªä¼´è€…: {caregiver}")

            notes = floating.get('å€‹æ¡ˆç¾æ³')
            if notes and len(notes) <= 80:
                summary_parts.append(f"ç¾æ³: {notes}")

            summary = " | ".join(p for p in summary_parts if p)
            # è¨˜éŒ„ç°¡è¦çš„éµæ•¸çµ±è¨ˆï¼Œä¾¿æ–¼åœ¨ dspy_internal_debug.log ä½è­‰
            try:
                self.logger.info(
                    "[DETAILS] fixed=%d keys, floating=%d keys (summary_len=%d)",
                    len(fixed) if isinstance(fixed, dict) else 0,
                    len(floating) if isinstance(floating, dict) else 0,
                    len(summary),
                )
            except Exception:
                pass

            return {
                'fixed_settings': fixed,
                'floating_settings': floating,
                'summary': summary
            }

        # ç„¡ details å¯ç”¨æ™‚ï¼šå›é€€åˆ°ç°¡çŸ­å­—ä¸²ï¼ˆç›¸å®¹èˆŠè¡Œç‚ºï¼‰
        fallback = [
            f"å§“å: {getattr(self.character, 'name', 'æœªçŸ¥')}",
            getattr(self.character, 'persona', ''),
            getattr(self.character, 'goal', ''),
        ]
        return " | ".join(part for part in fallback if part)
    
    def _process_optimized_prediction(self, prediction) -> dict:
        """è™•ç†å„ªåŒ–ç‰ˆé æ¸¬çµæœ"""
        try:
            responses = getattr(prediction, 'responses', [])
            state = self._normalize_state_value(getattr(prediction, 'state', 'NORMAL'))
            dialogue_context = self._normalize_text_field(
                getattr(prediction, 'dialogue_context', 'ä¸€èˆ¬å°è©±')
            )
            context_classification = self._normalize_context_value(
                getattr(prediction, 'context_classification', 'daily_routine_examples')
            ) or 'daily_routine_examples'
            processing_info = getattr(prediction, 'processing_info', None)

            # inferred_speaker_role å·²ç§»é™¤ï¼Œä¿æŒå‘å¾Œç›¸å®¹
            inferred_speaker_role = None
            
            # ç¢ºä¿å›æ‡‰æ ¼å¼æ­£ç¢º
            if isinstance(responses, str):
                try:
                    responses = json.loads(responses)
                except json.JSONDecodeError:
                    import ast as _ast
                    try:
                        parsed = _ast.literal_eval(responses)
                        if isinstance(parsed, list):
                            responses = parsed
                        else:
                            responses = [responses]
                    except Exception:
                        responses = [responses]
            
            if not isinstance(responses, list):
                responses = [str(responses)]

            normalized_list = []
            for item in responses:
                if isinstance(item, list):
                    normalized_list.extend([str(x) for x in item])
                    continue

                if isinstance(item, str):
                    s = item.strip()
                    if s.startswith('['):
                        candidate = s
                        if not s.endswith(']'):
                            closing = s.rfind(']')
                            if closing != -1:
                                candidate = s[:closing + 1]
                        parsed = None
                        try:
                            parsed = json.loads(candidate)
                        except json.JSONDecodeError:
                            import ast as _ast
                            try:
                                parsed = _ast.literal_eval(candidate)
                            except Exception:
                                parsed = None
                        if isinstance(parsed, list):
                            normalized_list.extend([str(x) for x in parsed])
                            remainder = s[len(candidate):].strip()
                            if remainder:
                                normalized_list.append(remainder)
                            continue
                        if s.startswith('{') and s.endswith('}'):
                            try:
                                parsed_obj = json.loads(s)
                                if isinstance(parsed_obj, dict) and 'responses' in parsed_obj:
                                    extracted = parsed_obj['responses']
                                    if isinstance(extracted, list):
                                        normalized_list.extend([str(x) for x in extracted])
                                        continue
                            except Exception:
                                pass
                    normalized_list.append(s)
                else:
                    normalized_list.append(str(item))

            responses = normalized_list[:4]
            responses = self._filter_chinese_responses(responses)

            return {
                "responses": responses,
                "state": state,
                "dialogue_context": dialogue_context,
                "context_classification": context_classification,
                "inferred_speaker_role": inferred_speaker_role,
                "processing_info": processing_info,
                "optimization_info": {
                    "api_calls_used": 1,
                    "api_calls_saved": 2,
                    "efficiency_improvement": "66.7%"
                }
            }
            
        except Exception as e:
            self.logger.error(f"å„ªåŒ–é æ¸¬çµæœè™•ç†å¤±æ•—: {e}", exc_info=True)
            return {
                "responses": [f"OptimizedPredictionError[{type(e).__name__}]: {e}"],
                "state": "ERROR",
                "dialogue_context": "OPTIMIZED_PREDICTION_EXCEPTION",
                "error": {
                    "type": type(e).__name__,
                    "message": str(e)
                }
            }
    
    def _update_dialogue_state(self, response_data: dict):
        """æ›´æ–°å°è©±ç‹€æ…‹"""
        try:
            from ..state import DialogueState
            new_state = response_data.get("state", "NORMAL")
            self.current_state = DialogueState(new_state)
            
            dialogue_context = response_data.get("dialogue_context", "")
            if dialogue_context:
                print(f"å„ªåŒ– DSPy åˆ¤æ–·çš„å°è©±æƒ…å¢ƒ: {dialogue_context}")
                
        except ValueError as e:
            self.logger.warning(f"ç„¡æ•ˆç‹€æ…‹ï¼Œè¨­ç½®ç‚º CONFUSED: {e}")
            from ..state import DialogueState
            self.current_state = DialogueState.CONFUSED
    
    def _handle_terminal_mode(self, user_input: str, response_data: dict) -> str:
        """è™•ç†çµ‚ç«¯æ©Ÿæ¨¡å¼çš„äº’å‹•"""
        import keyboard
        
        responses = response_data["responses"]
        
        print(f"\n{self.character.name} çš„å›æ‡‰é¸é …ï¼ˆå„ªåŒ– DSPy ç”Ÿæˆï¼Œç¯€çœ 66.7% API èª¿ç”¨ï¼‰ï¼š")
        for i, response in enumerate(responses, 1):
            print(f"{i}. {response}")
        print("0. é€™äº›é¸é …éƒ½ä¸é©åˆï¼ˆè·³éï¼Œç›´æ¥é€²å…¥ä¸‹ä¸€è¼ªå°è©±ï¼‰")
        print("q. çµæŸå°è©±")
        print("s. é¡¯ç¤ºå„ªåŒ–çµ±è¨ˆ")
        print("\nè«‹æŒ‰æ•¸å­—éµ 0-5 é¸æ“‡é¸é …ï¼Œs æŸ¥çœ‹çµ±è¨ˆï¼Œæˆ–æŒ‰ q çµæŸå°è©±...")
        
        while True:
            event = keyboard.read_event(suppress=True)
            if event.event_type == 'down':
                if event.name == '0':
                    print("\nè·³éæ­¤è¼ªå›æ‡‰ï¼Œè«‹ç¹¼çºŒå°è©±")
                    self.conversation_history.append("(è·³éæ­¤è¼ªå›æ‡‰)")
                    self.log_interaction(user_input, responses, selected_response="(è·³éæ­¤è¼ªå›æ‡‰)")
                    self.save_interaction_log()
                    return ""
                elif event.name == 'q':
                    print("\nçµæŸå°è©±")
                    print(self._get_optimization_summary())
                    self.save_interaction_log()
                    return "quit"
                elif event.name == 's':
                    print("\n" + self._get_optimization_summary())
                    continue
                elif event.name in ['1', '2', '3', '4', '5']:
                    choice = int(event.name)
                    if choice <= len(responses):
                        selected_response = responses[choice - 1]
                        print(f"\nå·²é¸æ“‡é¸é … {choice}: {selected_response}")
                        self.conversation_history.append(f"{self.character.name}: {selected_response}")
                        self.log_interaction(user_input, responses, selected_response=selected_response)
                        self.save_interaction_log()
                        return selected_response
    
    def _handle_gui_mode(self, user_input: str, response_data: dict, gui_selected_response: Optional[str] = None) -> str:
        """è™•ç† GUI æ¨¡å¼çš„äº’å‹•"""
        # Echo suppression: è‹¥æœ¬è¼ªè¼¸å…¥ç­‰åŒæ–¼æœ€è¿‘ç—…æ‚£ç™¼è¨€ï¼Œé¿å…å°‡å…¶è¨˜å…¥äº’å‹•æ—¥èªŒ
        suppress_logging = False
        try:
            normalized_input = (user_input or "").strip()
            if self.conversation_history and normalized_input:
                patient_prefix = f"{self.character.name}: "
                for entry in reversed(self.conversation_history):
                    if isinstance(entry, str):
                        s = entry.strip()
                        if s.startswith(patient_prefix):
                            last_patient_utterance = s[len(patient_prefix):].strip()
                            if last_patient_utterance == normalized_input:
                                suppress_logging = True
                            break
        except Exception:
            suppress_logging = False

        # è¨˜éŒ„äº’å‹•ï¼ˆè‹¥æœªè¢«å›è²æŠ‘åˆ¶ï¼‰
        if not suppress_logging:
            self.log_interaction(user_input, response_data["responses"], selected_response=gui_selected_response)
            self.save_interaction_log()

        # è¿”å› JSON æ ¼å¼å›æ‡‰
        return json.dumps(response_data, ensure_ascii=False)
    
    def get_optimization_statistics(self) -> dict:
        """ç²å–å„ªåŒ–çµ±è¨ˆè³‡è¨Š"""
        base_stats = {}
        if hasattr(self, 'dialogue_module') and hasattr(self.dialogue_module, 'get_unified_statistics'):
            base_stats = self.dialogue_module.get_unified_statistics()
        
        return {
            **base_stats,
            **self.optimization_stats,
            'optimization_enabled': self.optimization_enabled,
            'efficiency_summary': {
                'conversations_processed': self.optimization_stats['total_conversations'],
                'total_api_calls_saved': self.optimization_stats['api_calls_saved'],
                'quota_savings_percent': f"{self.optimization_stats['estimated_quota_saved_percent']:.1f}%",
                'calls_per_conversation': '1 (åŸæœ¬ 3æ¬¡)',
                'optimization_factor': '3x æ•ˆç‡æå‡'
            }
        }
    
    def _get_optimization_summary(self) -> str:
        """ç²å–å„ªåŒ–æ‘˜è¦å­—ä¸²"""
        stats = self.get_optimization_statistics()
        return f"""
ğŸ¯ API èª¿ç”¨å„ªåŒ–çµ±è¨ˆæ‘˜è¦:
  - è™•ç†å°è©±æ•¸é‡: {stats['conversations_processed']}
  - ç¯€çœ API èª¿ç”¨: {stats['total_api_calls_saved']} æ¬¡
  - é…é¡ç¯€çœç‡: {stats['quota_savings_percent']}
  - æ•ˆç‡æå‡: æ¯æ¬¡å°è©±å¾ 3æ¬¡èª¿ç”¨ â†’ 1æ¬¡èª¿ç”¨
  - æ•´é«”æ•ˆç‡: æå‡ 3å€ï¼Œè§£æ±ºé…é¡é™åˆ¶å•é¡Œ
"""
    
    # å·²ç§»é™¤ï¼šé€€åŒ–é˜²è­·å±¤
    
    # ç°¡åŒ–ï¼šç§»é™¤æœªä½¿ç”¨çš„ä¸Šä¸‹æ–‡é‡ç½®åŠŸèƒ½


    def _normalize_responses(self, responses) -> list:
        if isinstance(responses, str):
            return [responses.strip()] if responses.strip() else []
        if isinstance(responses, list):
            return [str(item).strip() for item in responses if str(item).strip()]
        if responses is None:
            return []
        return [str(responses).strip()]

    def _normalize_state_value(self, raw_state: Any) -> str:
        allowed = {'NORMAL', 'CONFUSED', 'TRANSITIONING', 'TERMINATED'}

        if isinstance(raw_state, dict):
            return self._normalize_state_value(raw_state.get('state') or raw_state.get('name'))
        if isinstance(raw_state, (list, tuple)):
            for item in raw_state:
                normalized = self._normalize_state_value(item)
                if normalized:
                    return normalized
            return 'NORMAL'
        if raw_state is None:
            return 'NORMAL'

        candidate = str(raw_state).strip().upper()
        if candidate in allowed:
            return candidate
        return 'NORMAL'

    def _normalize_text_field(self, value: Any) -> str:
        if isinstance(value, dict):
            for key in ('dialogue_context', 'value', 'text', 'description'):
                if key in value:
                    return self._normalize_text_field(value[key])
            return json.dumps(value, ensure_ascii=False)
        if isinstance(value, (list, tuple)):
            return " | ".join(self._normalize_text_field(v) for v in value if v)
        return str(value).strip() if value is not None else ''

    def _normalize_context_value(self, value: Any) -> Optional[str]:
        if isinstance(value, dict):
            for key in ('context_classification', 'label', 'id', 'name', 'value'):
                if key in value:
                    return self._normalize_context_value(value[key])
            return None
        if isinstance(value, (list, tuple)):
            for item in value:
                normalized = self._normalize_context_value(item)
                if normalized:
                    return normalized
            return None
        if isinstance(value, str):
            stripped = value.strip()
            if not stripped:
                return None
            if stripped.startswith('{') and stripped.endswith('}'):
                try:
                    parsed = json.loads(stripped)
                    return self._normalize_context_value(parsed)
                except Exception:
                    return None
            return stripped
        return None

    def _filter_chinese_responses(self, responses: List[str]) -> List[str]:
        chinese_regex = re.compile(r"[\u4e00-\u9fff]")
        filtered: List[str] = [r for r in responses if chinese_regex.search(r)]
        if filtered:
            if len(filtered) < len(responses):
                self.logger.info(
                    "âš ï¸ Removed non-Chinese responses: %s",
                    [r for r in responses if r not in filtered],
                )
            return filtered[:4]
        return responses

    def _attempt_sensitive_rewrite(self, original_question: str, base_prediction=None):
        """Ask Gemini to rewrite the question and fetch a new response."""
        try:
            if not self.enable_sensitive_rewrite:
                return None

            if not hasattr(self, 'sensitive_question_module'):
                return None

            conversation_summary = "\n".join(self.conversation_history[-6:])
            rewrite_prediction = self.sensitive_question_module.rewrite(
                original_question=original_question,
                conversation_summary=conversation_summary,
                character_name=self.character.name,
                character_persona=self.character.persona,
            )

            if not rewrite_prediction:
                self.logger.warning("Sensitive rewrite module returned None")
                return None

            sensitivity_flag = str(getattr(rewrite_prediction, 'sensitivity_flag', '')).strip()
            rewritten_question = str(getattr(rewrite_prediction, 'rewritten_question', '')).strip()
            reason = str(getattr(rewrite_prediction, 'sensitivity_reason', '')).strip()
            reassurance = str(getattr(rewrite_prediction, 'reassurance_message', '')).strip()

            normalized_flag = sensitivity_flag.upper()
            should_use_rewrite = normalized_flag in {'YES', 'TRUE', 'SENSITIVE'} and rewritten_question

            if not should_use_rewrite:
                self.logger.warning(
                    "Sensitive rewrite probe completed but flag=%s (reason=%s); skipping fallback.",
                    sensitivity_flag or 'UNKNOWN',
                    reason or 'æœªæä¾›',
                )
                return None

            self.logger.warning(
                "Gemini policy refusal detected. Reason: %s", reason or 'æœªæä¾›'
            )
            self.logger.warning(
                "Original question: %s | Rewritten as: %s",
                original_question,
                rewritten_question,
            )

            # Replace the last caregiver entry with the rewritten question for context continuity
            if self.conversation_history and self.conversation_history[-1].startswith("å°è©±æ–¹: "):
                self.conversation_history[-1] = f"å°è©±æ–¹(é‡è¿°): {rewritten_question}"
            else:
                self.conversation_history.append(f"å°è©±æ–¹(é‡è¿°): {rewritten_question}")

            rewritten_prediction = self.dialogue_module(
                user_input=rewritten_question,
                character_name=self.character.name,
                character_persona=self.character.persona,
                character_backstory=self.character.backstory,
                character_goal=self.character.goal,
                character_details=self._get_character_details(),
                conversation_history=self._format_conversation_history()
            )

            response_data = self._process_optimized_prediction(rewritten_prediction)
            response_data["sensitive_rewrite_applied"] = True
            response_data["sensitive_rewrite"] = {
                "original_question": original_question,
                "rewritten_question": rewritten_question,
                "reason": reason,
                "reassurance": reassurance,
            }

            explanation = reason or "åŸå§‹æå•å¯èƒ½è§¸åŠæ•æ„Ÿæ”¿ç­–"
            notice = f"æé†’ï¼š{explanation}ã€‚å·²æ”¹å¯«ç‚ºã€Œ{rewritten_question}ã€ã€‚"
            if reassurance:
                notice = f"{notice} {reassurance}"

            rewritten_responses = response_data.get("responses", [])
            enriched = [notice] + rewritten_responses
            response_data["responses"] = enriched[:4]
            return response_data

        except Exception as exc:  # pragma: no cover - defensive logging
            self.logger.error(f"Sensitive rewrite flow failed: {exc}", exc_info=True)
            return None
    
    def _track_session_state_changes(self, user_input: str, response_data: dict, round_number: int):
        """è¿½è¹¤æœƒè©±ç‹€æ…‹è®ŠåŒ–å’Œé€€åŒ–æŒ‡æ¨™
        
        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥
            response_data: å›æ‡‰è³‡æ–™
            round_number: å°è©±è¼ªæ¬¡
        """
        try:
            self.logger.info(f"=== SESSION STATE TRACKING - Round {round_number} ===")
            
            # åŸºæœ¬æœƒè©±è³‡è¨Š
            self.logger.info(f"ğŸ”¢ CONVERSATION METRICS:")
            self.logger.info(f"  ğŸ“Š Round Number: {round_number}")
            self.logger.info(f"  ğŸ“ˆ Total Conversation History: {len(self.conversation_history)} entries")
            self.logger.info(f"  ğŸ“ Current Input Length: {len(user_input)} chars")
            
            # æœƒè©±ç‹€æ…‹åˆ†æ
            session_state = self._analyze_session_state(response_data, round_number)
            self.logger.info(f"  ğŸ­ Session State Analysis:")
            for key, value in session_state.items():
                self.logger.info(f"    {key}: {value}")
            
            # è§’è‰²ä¸€è‡´æ€§è¿½è¹¤
            consistency_score = self._calculate_consistency_score(response_data)
            self.logger.info(f"  ğŸ¯ Character Consistency Score: {consistency_score:.3f}")
            
            # å›æ‡‰å“è³ªæŒ‡æ¨™
            quality_metrics = self._calculate_response_quality_metrics(response_data)
            self.logger.info(f"  ğŸ† Response Quality Metrics:")
            for metric, value in quality_metrics.items():
                self.logger.info(f"    {metric}: {value}")
            
            # ç°¡åŒ–ï¼šç§»é™¤é€€åŒ–é¢¨éšª/è¤‡é›œåº¦/è¨˜æ†¶é«”èˆ‡é—œéµè¼ªåˆ†æåŠç‹€æ…‹æ­·å²è¨˜éŒ„
            
        except Exception as e:
            self.logger.error(f"æœƒè©±ç‹€æ…‹è¿½è¹¤å¤±æ•—: {e}")
    
    def _analyze_session_state(self, response_data: dict, round_number: int) -> dict:
        """åˆ†æç•¶å‰æœƒè©±ç‹€æ…‹"""
        try:
            responses = response_data.get("responses", [])
            state = response_data.get("state", "UNKNOWN")
            context = response_data.get("dialogue_context", "UNKNOWN")
            
            return {
                "Response_Count": len(responses),
                "Dialogue_State": state,
                "Dialogue_Context": context,
                "Round_Number": round_number,
                "Original_Degradation": response_data.get("original_degradation", []),
                "Emergency_Recovery": response_data.get("emergency_recovery", False)
            }
        except Exception as e:
            return {"Error": str(e)}
    
    def _calculate_consistency_score(self, response_data: dict) -> float:
        """è¨ˆç®—è§’è‰²ä¸€è‡´æ€§åˆ†æ•¸"""
        try:
            responses = response_data.get("responses", [])
            if not responses:
                return 0.0
            
            score = 1.0
            
            # æª¢æŸ¥è‡ªæˆ‘ä»‹ç´¹æ¨¡å¼ï¼ˆåš´é‡æ‰£åˆ†ï¼‰
            for response in responses:
                if any(pattern in str(response) for pattern in ["æˆ‘æ˜¯Patient", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯"]):
                    score -= 0.4
                    break
            
            # æª¢æŸ¥é€šç”¨å›æ‡‰ï¼ˆä¸­åº¦æ‰£åˆ†ï¼‰
            for response in responses:
                if any(pattern in str(response) for pattern in ["æ²’æœ‰å®Œå…¨ç†è§£", "æ›å€‹æ–¹å¼èªªæ˜", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©"]):
                    score -= 0.2
                    break
            
            # æª¢æŸ¥é†«ç™‚ç›¸é—œæ€§ï¼ˆåŠ åˆ†ï¼‰
            medical_terms = ["ç—‡ç‹€", "æª¢æŸ¥", "å‚·å£", "æ¢å¾©", "æ²»ç™‚", "è—¥ç‰©", "è­·ç†"]
            has_medical_context = any(
                any(term in str(response) for term in medical_terms)
                for response in responses
            )
            if has_medical_context:
                score += 0.1
            
            return max(0.0, min(1.0, score))
            
        except Exception:
            return 0.5
    
    def _calculate_response_quality_metrics(self, response_data: dict) -> dict:
        """è¨ˆç®—å›æ‡‰å“è³ªæŒ‡æ¨™"""
        try:
            responses = response_data.get("responses", [])
            
            metrics = {
                "Response_Count": len(responses),
                "Average_Length": sum(len(str(r)) for r in responses) // max(1, len(responses)),
            }
            
            return metrics
            
        except Exception as e:
            return {"Error": str(e)}

    
    
    # ç°¡åŒ–ï¼šç§»é™¤é€€åŒ–é¢¨éšª/è¤‡é›œåº¦/è¨˜æ†¶é«”èˆ‡é—œéµè¼ªåˆ†æèˆ‡ç‹€æ…‹æ­·å²æ–¹æ³•ï¼ˆç„¡è¡Œç‚ºå½±éŸ¿ï¼‰
    
    def _generate_emergency_response(self, user_input: str) -> str:
        """ç”Ÿæˆç·Šæ€¥æ¢å¾©å›æ‡‰ï¼Œç•¶æ‰€æœ‰å…¶ä»–æ–¹æ³•éƒ½å¤±æ•—æ™‚ä½¿ç”¨"""
        self.logger.warning(f"ğŸš¨ ç”Ÿæˆç·Šæ€¥æ¢å¾©å›æ‡‰ for: {user_input}")
        emergency_responses = [
            "EmergencyFallback: dialogue manager failed to recover; please review server logs."
        ]

        emergency_data = {
            "status": "success",
            "responses": emergency_responses,
            "state": "NORMAL", 
            "dialogue_context": "ç·Šæ€¥æ¢å¾©æ¨¡å¼",
            "session_id": getattr(self, 'current_session_id', None),
            "emergency_recovery": True,
            "speech_recognition_options": None,
            "original_transcription": None
        }
        
        return json.dumps(emergency_data, ensure_ascii=False)

    def cleanup(self):
        """æ¸…ç†è³‡æº"""
        self.logger.info("æ¸…ç†å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨")
        
        # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
        final_stats = self.get_optimization_statistics()
        self.logger.info(f"æœ€çµ‚å„ªåŒ–çµ±è¨ˆ: {final_stats}")
        
        if hasattr(self, 'dialogue_module') and hasattr(self.dialogue_module, 'cleanup'):
            self.dialogue_module.cleanup()


# æ¸¬è©¦å‡½æ•¸
def test_optimized_dialogue_manager():
    """æ¸¬è©¦å„ªåŒ–ç‰ˆå°è©±ç®¡ç†å™¨"""
    print("ğŸ§ª æ¸¬è©¦å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨...")
    
    try:
        # å‰µå»ºæ¸¬è©¦è§’è‰²
        from ..character import Character
        test_character = Character(
            name="æ¸¬è©¦ç—…æ‚£",
            persona="å‹å–„ä½†æ“”å¿ƒçš„ç—…æ‚£",
            backstory="ä½é™¢ä¸­é€²è¡Œåº·å¾©æ²»ç™‚",
            goal="ç›¡å¿«åº·å¾©å‡ºé™¢"
        )
        
        # å‰µå»ºå„ªåŒ–ç‰ˆç®¡ç†å™¨
        manager = OptimizedDialogueManagerDSPy(test_character)
        
        print("âœ… å„ªåŒ–ç‰ˆå°è©±ç®¡ç†å™¨å‰µå»ºæˆåŠŸ")
        print(manager._get_optimization_summary())
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_optimized_dialogue_manager()

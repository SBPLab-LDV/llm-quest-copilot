#!/usr/bin/env python3
"""
å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨

ä½¿ç”¨çµ±ä¸€å°è©±æ¨¡çµ„ï¼Œå°‡ API èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ï¼Œ
è§£æ±º Gemini API é…é¡é™åˆ¶å•é¡Œã€‚
"""

import json
import logging
import re
import time
from typing import Any, Dict, List, Optional, Union

from ..dialogue import DialogueManager
from ..character import Character
from .unified_dialogue_module import UnifiedDSPyDialogueModule
from .sensitive_question_module import SensitiveQuestionRewriteModule
from .config import get_config

logger = logging.getLogger(__name__)


class OptimizedDialogueManagerDSPy(DialogueManager):
    """å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨

    ä¸»è¦å„ªåŒ–ï¼š
    - API èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ (ç¯€çœ 66.7% é…é¡ä½¿ç”¨)
    - ä¿æŒå®Œå…¨çš„ API å…¼å®¹æ€§
    - æä¾›è©³ç´°çš„ç¯€çœçµ±è¨ˆ
    """
    
    def __init__(self, character: Character, use_terminal: bool = False, log_dir: str = "logs"):
        """åˆå§‹åŒ–å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨
        
        Args:
            character: Character instance containing the NPC's information (as patient identifier)
            use_terminal: Whether to use terminal mode for interaction
            log_dir: Directory to save interaction logs
        """
        # åˆå§‹åŒ–çˆ¶é¡
        super().__init__(character, use_terminal, log_dir)
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("OptimizedDialogueManagerDSPy.__init__ - ä½¿ç”¨çµ±ä¸€å°è©±æ¨¡çµ„")
        
        # è®€å–æ•æ„Ÿæå•æ”¹å¯«é–‹é—œ
        dspy_config = get_config().get_dspy_config()
        self.enable_sensitive_rewrite = dspy_config.get('enable_sensitive_rewrite', True)

        # åˆå§‹åŒ–å„ªåŒ–çš„ DSPy çµ„ä»¶
        try:
            self.dialogue_module = UnifiedDSPyDialogueModule()
            self.optimization_enabled = True
            self.logger.info("å„ªåŒ–çµ±ä¸€å°è©±æ¨¡çµ„åˆå§‹åŒ–æˆåŠŸ - API èª¿ç”¨ç¯€çœ 66.7%")
            if self.enable_sensitive_rewrite:
                self.sensitive_question_module = SensitiveQuestionRewriteModule()
            else:
                self.sensitive_question_module = None
                self.logger.info("æ•æ„Ÿæå•æ”¹å¯«å·²åœç”¨ï¼ˆenable_sensitive_rewrite=Falseï¼‰")
        except Exception as e:
            self.logger.error(f"çµ±ä¸€å°è©±æ¨¡çµ„åˆå§‹åŒ–å¤±æ•—: {e}")
            self.optimization_enabled = False
            # å›é€€åˆ°åŸå§‹å¯¦ç¾
            from .dialogue_manager_dspy import DialogueManagerDSPy
            fallback_manager = DialogueManagerDSPy(character, use_terminal, log_dir)
            self.dialogue_module = fallback_manager.dialogue_module
            if self.enable_sensitive_rewrite:
                self.sensitive_question_module = getattr(
                    fallback_manager,
                    'sensitive_question_module',
                    SensitiveQuestionRewriteModule(),
                )
            else:
                self.sensitive_question_module = None
            self.logger.warning("å·²å›é€€åˆ°åŸå§‹ DSPy å¯¦ç¾")
        
        # çµ±è¨ˆè¿½è¹¤
        self.optimization_stats = {
            'total_conversations': 0,
            'api_calls_saved': 0,
            'estimated_quota_saved_percent': 0.0
        }
        self._character_profile_emitted = False

    async def process_turn(self, user_input: str, gui_selected_response: Optional[str] = None) -> Union[str, dict]:
        """è™•ç†å„ªåŒ–ç‰ˆå°è©±è¼ªæ¬¡
        
        Args:
            user_input: The user's input text
            gui_selected_response: Selected response in GUI mode (optional)
            
        Returns:
            Either a string response (terminal mode) or JSON response (GUI mode)
        """
        if not self.optimization_enabled:
            # å›é€€åˆ°çˆ¶é¡å¯¦ç¾
            return await super().process_turn(user_input, gui_selected_response)
        
        self.optimization_stats['total_conversations'] += 1
        
        try:
            self.logger.info(f"=== å„ªåŒ–ç‰ˆå°è©±è™•ç† (ç¬¬ {self.optimization_stats['total_conversations']} æ¬¡) ===")
            self.logger.info(f"ç”¨æˆ¶è¼¸å…¥: {user_input}")
            
            # æª¢æŸ¥é‡è¤‡è¼¸å…¥ - é¿å…åœ¨æœƒè©±ä¸­æ·»åŠ ç›¸åŒçš„è¼¸å…¥
            last_user_input = None
            if self.conversation_history:
                for entry in reversed(self.conversation_history):
                    if entry.startswith("è­·ç†äººå“¡: "):
                        last_user_input = entry[5:]  # ç§»é™¤ "è­·ç†äººå“¡: " å‰ç¶´
                        break
            
            is_duplicate_input = (last_user_input == user_input)
            
            # åªæœ‰ä¸æ˜¯é‡è¤‡è¼¸å…¥æ™‚æ‰è¨˜éŒ„åˆ°å°è©±æ­·å²
            if not is_duplicate_input:
                self.conversation_history.append(f"è­·ç†äººå“¡: {user_input}")
                self.logger.info(f"âœ… æ–°è¼¸å…¥å·²è¨˜éŒ„åˆ°å°è©±æ­·å²")
            else:
                self.logger.info(f"âš ï¸ æª¢æ¸¬åˆ°é‡è¤‡è¼¸å…¥ï¼Œè·³éè¨˜éŒ„åˆ°å°è©±æ­·å²ï¼Œé¿å…æ··äº‚")
            
            # ä½¿ç”¨å„ªåŒ–çš„çµ±ä¸€å°è©±æ¨¡çµ„ (åƒ…1æ¬¡ API èª¿ç”¨)
            prediction = self.dialogue_module(
                user_input=user_input,
                character_name=self.character.name,
                character_persona=self.character.persona,
                character_backstory=self.character.backstory,
                character_goal=self.character.goal,
                character_details=self._get_character_details(),
                conversation_history=self._format_conversation_history()
            )
            
            self.logger.info(f"å„ªåŒ–è™•ç†å®Œæˆ:")
            self.logger.info(f"  - API èª¿ç”¨æ¬¡æ•¸: 1 (åŸæœ¬éœ€è¦ 3æ¬¡)")
            self.logger.info(f"  - ç¯€çœé…é¡ä½¿ç”¨: 66.7%")
            self.logger.info(f"  - å›æ‡‰æ•¸é‡: {len(prediction.responses)}")
            self.logger.info(f"  - æƒ…å¢ƒåˆ†é¡: {prediction.context_classification}")
            
            # æ›´æ–°ç¯€çœçµ±è¨ˆ
            saved_calls = prediction.processing_info.get('api_calls_saved', 2)
            self.optimization_stats['api_calls_saved'] += saved_calls
            self.optimization_stats['estimated_quota_saved_percent'] = (
                (self.optimization_stats['api_calls_saved'] / 
                 (self.optimization_stats['total_conversations'] * 3)) * 100
                if self.optimization_stats['total_conversations'] > 0 else 0
            )
            
            # è®“ rewrite æ¨¡çµ„æ±ºç­–æ˜¯å¦éœ€è¦æ”¹å¯«
            rewrite_result = self._attempt_sensitive_rewrite(user_input, prediction)

            if rewrite_result:
                response_data = rewrite_result
            else:
                response_data = self._process_optimized_prediction(prediction)

            # åƒ…ç›£æ¸¬é€€åŒ–ç‹€æ…‹ï¼Œä¸æ”¹å¯«å›æ‡‰å…§å®¹
            response_data = self._apply_degradation_prevention(response_data, user_input)
            
            # ====== Phase 1.3: æœƒè©±ç‹€æ…‹è®ŠåŒ–è¿½è¹¤ ======
            round_number = len(self.conversation_history) // 2 + 1  # ä¼°ç®—è¼ªæ¬¡
            self._track_session_state_changes(user_input, response_data, round_number)
            
            # æ›´æ–°å°è©±ç‹€æ…‹
            self._update_dialogue_state(response_data)
            
            # è™•ç†çµ‚ç«¯æ©Ÿæ¨¡å¼æˆ– GUI æ¨¡å¼
            if self.use_terminal:
                return self._handle_terminal_mode(user_input, response_data)
            else:
                return self._handle_gui_mode(user_input, response_data, gui_selected_response)
                
        except Exception as e:
            self.logger.error(f"å„ªåŒ–ç‰ˆå°è©±è™•ç†å¤±æ•—: {e}")
            self.logger.error("UNIFIED_FAILED: OptimizedDialogueManagerDSPy.process_turn exception", exc_info=True)
            
            # å˜—è©¦å¾çˆ¶é¡ç²å–å›æ‡‰ï¼Œç„¶å¾Œæ‡‰ç”¨é€€åŒ–é˜²è­·
            try:
                fallback_result = await super().process_turn(user_input, gui_selected_response)
                
                # å¦‚æœçˆ¶é¡è¿”å› JSON å­—ä¸²ï¼Œè§£æå®ƒ
                if isinstance(fallback_result, str):
                    try:
                        fallback_data = json.loads(fallback_result)
                        # æ‡‰ç”¨é€€åŒ–é˜²è­·åˆ°çˆ¶é¡å›æ‡‰
                        protected_data = self._apply_degradation_prevention(fallback_data, user_input)
                        return json.dumps(protected_data, ensure_ascii=False)
                    except json.JSONDecodeError:
                        # ä¸æ˜¯ JSONï¼Œç›´æ¥è¿”å›
                        return fallback_result
                else:
                    # çˆ¶é¡è¿”å›å­—å…¸ï¼Œç›´æ¥æ‡‰ç”¨é˜²è­·
                    return self._apply_degradation_prevention(fallback_result, user_input)
                    
            except Exception as fallback_error:
                self.logger.error(f"çˆ¶é¡å›é€€ä¹Ÿå¤±æ•—: {fallback_error}")
                self.logger.error("FALLBACK_CHAIN_FAILED: super().process_turn exception", exc_info=True)
                # æœ€çµ‚é˜²è­·ï¼šç”Ÿæˆå®‰å…¨çš„æ¢å¾©å›æ‡‰
                return self._generate_emergency_response(user_input)
    
    def _get_character_details(self) -> str:
        """å›å‚³ç°¡æ½”çš„è§’è‰²æ‘˜è¦ä¾›æç¤ºä½¿ç”¨ã€‚"""
        summary_parts: List[str] = []

        details_dict: Optional[Dict[str, Any]] = None
        try:
            if isinstance(self.character.details, dict) and self.character.details:
                details_dict = self.character.details
            elif isinstance(self.character.details, str) and self.character.details.strip():
                details_dict = json.loads(self.character.details)
        except Exception:
            details_dict = None

        if details_dict:
            fixed = details_dict.get('fixed_settings') or {}
            floating = details_dict.get('floating_settings') or {}

            name = fixed.get('å§“å') or getattr(self.character, 'name', '')
            diagnosis = fixed.get('è¨ºæ–·') or fixed.get('ç›®å‰è¨ºæ–·') or ''
            staging = fixed.get('åˆ†æœŸ') or fixed.get('è¨ºæ–·åˆ†æœŸ') or ''
            summary_parts.append(
                "å§“å: {name} / è¨ºæ–·: {diag}{stage}".format(
                    name=name or getattr(self.character, 'name', 'æœªçŸ¥'),
                    diag=diagnosis,
                    stage=f" ({staging})" if staging else ""
                ).strip()
            )

            treatment_stage = floating.get('ç›®å‰æ²»ç™‚éšæ®µ') or floating.get('æ²»ç™‚éšæ®µ') or ''
            treatment_status = floating.get('ç›®å‰æ²»ç™‚ç‹€æ…‹') or ''
            if treatment_stage or treatment_status:
                line = "ç›®å‰æ²»ç™‚éšæ®µ: {stage}".format(stage=treatment_stage or treatment_status)
                if treatment_stage and treatment_status and treatment_status != treatment_stage:
                    line += f"ï¼›ç‹€æ…‹: {treatment_status}"
                summary_parts.append(line)

            caregiver = floating.get('ä¸»è¦ç…§é¡§è€…') or floating.get('é™ªä¼´è€…')
            if caregiver:
                summary_parts.append(f"é™ªä¼´è€…: {caregiver}")

            notes = floating.get('å€‹æ¡ˆç¾æ³')
            if notes and len(notes) <= 80:
                summary_parts.append(f"ç¾æ³: {notes}")

        if not summary_parts:
            fallback = [
                f"å§“å: {getattr(self.character, 'name', 'æœªçŸ¥')}",
                getattr(self.character, 'persona', ''),
                getattr(self.character, 'goal', ''),
            ]
            summary_parts.extend(part for part in fallback if part)

        summary = " | ".join(summary_parts)

        if not self._character_profile_emitted:
            self._character_profile_emitted = True
            return summary

        return ""
    
    def _process_optimized_prediction(self, prediction) -> dict:
        """è™•ç†å„ªåŒ–ç‰ˆé æ¸¬çµæœ"""
        try:
            responses = getattr(prediction, 'responses', [])
            state = self._normalize_state_value(getattr(prediction, 'state', 'NORMAL'))
            dialogue_context = self._normalize_text_field(
                getattr(prediction, 'dialogue_context', 'ä¸€èˆ¬å°è©±')
            )
            context_classification = self._normalize_context_value(
                getattr(prediction, 'context_classification', 'daily_routine_examples')
            ) or 'daily_routine_examples'
            processing_info = getattr(prediction, 'processing_info', None)
            
            # ç¢ºä¿å›æ‡‰æ ¼å¼æ­£ç¢º
            if isinstance(responses, str):
                try:
                    responses = json.loads(responses)
                except json.JSONDecodeError:
                    import ast as _ast
                    try:
                        parsed = _ast.literal_eval(responses)
                        if isinstance(parsed, list):
                            responses = parsed
                        else:
                            responses = [responses]
                    except Exception:
                        responses = [responses]
            
            if not isinstance(responses, list):
                responses = [str(responses)]

            normalized_list = []
            for item in responses:
                if isinstance(item, list):
                    normalized_list.extend([str(x) for x in item])
                    continue

                if isinstance(item, str):
                    s = item.strip()
                    if s.startswith('['):
                        candidate = s
                        if not s.endswith(']'):
                            closing = s.rfind(']')
                            if closing != -1:
                                candidate = s[:closing + 1]
                        parsed = None
                        try:
                            parsed = json.loads(candidate)
                        except json.JSONDecodeError:
                            import ast as _ast
                            try:
                                parsed = _ast.literal_eval(candidate)
                            except Exception:
                                parsed = None
                        if isinstance(parsed, list):
                            normalized_list.extend([str(x) for x in parsed])
                            remainder = s[len(candidate):].strip()
                            if remainder:
                                normalized_list.append(remainder)
                            continue
                        if s.startswith('{') and s.endswith('}'):
                            try:
                                parsed_obj = json.loads(s)
                                if isinstance(parsed_obj, dict) and 'responses' in parsed_obj:
                                    extracted = parsed_obj['responses']
                                    if isinstance(extracted, list):
                                        normalized_list.extend([str(x) for x in extracted])
                                        continue
                            except Exception:
                                pass
                    normalized_list.append(s)
                else:
                    normalized_list.append(str(item))

            responses = normalized_list[:5]
            responses = self._filter_chinese_responses(responses)
            responses = self._enforce_response_constraints(responses)

            return {
                "responses": responses,
                "state": state,
                "dialogue_context": dialogue_context,
                "context_classification": context_classification,
                "processing_info": processing_info,
                "optimization_info": {
                    "api_calls_used": 1,
                    "api_calls_saved": 2,
                    "efficiency_improvement": "66.7%"
                }
            }
            
        except Exception as e:
            self.logger.error(f"å„ªåŒ–é æ¸¬çµæœè™•ç†å¤±æ•—: {e}", exc_info=True)
            return {
                "responses": [f"OptimizedPredictionError[{type(e).__name__}]: {e}"],
                "state": "ERROR",
                "dialogue_context": "OPTIMIZED_PREDICTION_EXCEPTION",
                "error": {
                    "type": type(e).__name__,
                    "message": str(e)
                }
            }
    
    def _update_dialogue_state(self, response_data: dict):
        """æ›´æ–°å°è©±ç‹€æ…‹"""
        try:
            from ..state import DialogueState
            new_state = response_data.get("state", "NORMAL")
            self.current_state = DialogueState(new_state)
            
            dialogue_context = response_data.get("dialogue_context", "")
            if dialogue_context:
                print(f"å„ªåŒ– DSPy åˆ¤æ–·çš„å°è©±æƒ…å¢ƒ: {dialogue_context}")
                
        except ValueError as e:
            self.logger.warning(f"ç„¡æ•ˆç‹€æ…‹ï¼Œè¨­ç½®ç‚º CONFUSED: {e}")
            from ..state import DialogueState
            self.current_state = DialogueState.CONFUSED
    
    def _handle_terminal_mode(self, user_input: str, response_data: dict) -> str:
        """è™•ç†çµ‚ç«¯æ©Ÿæ¨¡å¼çš„äº’å‹•"""
        import keyboard
        
        responses = response_data["responses"]
        
        print(f"\n{self.character.name} çš„å›æ‡‰é¸é …ï¼ˆå„ªåŒ– DSPy ç”Ÿæˆï¼Œç¯€çœ 66.7% API èª¿ç”¨ï¼‰ï¼š")
        for i, response in enumerate(responses, 1):
            print(f"{i}. {response}")
        print("0. é€™äº›é¸é …éƒ½ä¸é©åˆï¼ˆè·³éï¼Œç›´æ¥é€²å…¥ä¸‹ä¸€è¼ªå°è©±ï¼‰")
        print("q. çµæŸå°è©±")
        print("s. é¡¯ç¤ºå„ªåŒ–çµ±è¨ˆ")
        print("\nè«‹æŒ‰æ•¸å­—éµ 0-5 é¸æ“‡é¸é …ï¼Œs æŸ¥çœ‹çµ±è¨ˆï¼Œæˆ–æŒ‰ q çµæŸå°è©±...")
        
        while True:
            event = keyboard.read_event(suppress=True)
            if event.event_type == 'down':
                if event.name == '0':
                    print("\nè·³éæ­¤è¼ªå›æ‡‰ï¼Œè«‹ç¹¼çºŒå°è©±")
                    self.conversation_history.append("(è·³éæ­¤è¼ªå›æ‡‰)")
                    self.log_interaction(user_input, responses, selected_response="(è·³éæ­¤è¼ªå›æ‡‰)")
                    self.save_interaction_log()
                    return ""
                elif event.name == 'q':
                    print("\nçµæŸå°è©±")
                    print(self._get_optimization_summary())
                    self.save_interaction_log()
                    return "quit"
                elif event.name == 's':
                    print("\n" + self._get_optimization_summary())
                    continue
                elif event.name in ['1', '2', '3', '4', '5']:
                    choice = int(event.name)
                    if choice <= len(responses):
                        selected_response = responses[choice - 1]
                        print(f"\nå·²é¸æ“‡é¸é … {choice}: {selected_response}")
                        self.conversation_history.append(f"{self.character.name}: {selected_response}")
                        self.log_interaction(user_input, responses, selected_response=selected_response)
                        self.save_interaction_log()
                        return selected_response
    
    def _handle_gui_mode(self, user_input: str, response_data: dict, gui_selected_response: Optional[str] = None) -> str:
        """è™•ç† GUI æ¨¡å¼çš„äº’å‹•"""
        # è¨˜éŒ„äº’å‹•
        self.log_interaction(user_input, response_data["responses"], selected_response=gui_selected_response)
        self.save_interaction_log()
        
        # è¿½åŠ ç—…æ‚£å›æ‡‰åˆ°å°è©±æ­·å²ï¼ˆé¸æ“‡é¦–å€‹å»ºè­°ï¼Œä¾¿æ–¼ä¸‹ä¸€è¼ªæä¾›ä¸Šä¸‹æ–‡ï¼‰
        try:
            normalized = self._normalize_responses(response_data.get("responses", []))
            if normalized:
                self.conversation_history.append(f"{self.character.name}: {normalized[0]}")
        except Exception:
            pass
        
        # è¿”å› JSON æ ¼å¼å›æ‡‰
        return json.dumps(response_data, ensure_ascii=False)
    
    def get_optimization_statistics(self) -> dict:
        """ç²å–å„ªåŒ–çµ±è¨ˆè³‡è¨Š"""
        base_stats = {}
        if hasattr(self, 'dialogue_module') and hasattr(self.dialogue_module, 'get_unified_statistics'):
            base_stats = self.dialogue_module.get_unified_statistics()
        
        return {
            **base_stats,
            **self.optimization_stats,
            'optimization_enabled': self.optimization_enabled,
            'efficiency_summary': {
                'conversations_processed': self.optimization_stats['total_conversations'],
                'total_api_calls_saved': self.optimization_stats['api_calls_saved'],
                'quota_savings_percent': f"{self.optimization_stats['estimated_quota_saved_percent']:.1f}%",
                'calls_per_conversation': '1 (åŸæœ¬ 3æ¬¡)',
                'optimization_factor': '3x æ•ˆç‡æå‡'
            }
        }
    
    def _get_optimization_summary(self) -> str:
        """ç²å–å„ªåŒ–æ‘˜è¦å­—ä¸²"""
        stats = self.get_optimization_statistics()
        return f"""
ğŸ¯ API èª¿ç”¨å„ªåŒ–çµ±è¨ˆæ‘˜è¦:
  - è™•ç†å°è©±æ•¸é‡: {stats['conversations_processed']}
  - ç¯€çœ API èª¿ç”¨: {stats['total_api_calls_saved']} æ¬¡
  - é…é¡ç¯€çœç‡: {stats['quota_savings_percent']}
  - æ•ˆç‡æå‡: æ¯æ¬¡å°è©±å¾ 3æ¬¡èª¿ç”¨ â†’ 1æ¬¡èª¿ç”¨
  - æ•´é«”æ•ˆç‡: æå‡ 3å€ï¼Œè§£æ±ºé…é¡é™åˆ¶å•é¡Œ
"""
    
    def _apply_degradation_prevention(self, response_data: dict, user_input: str) -> dict:
        """æ‡‰ç”¨é€€åŒ–é˜²è­·æªæ–½ï¼Œæª¢æ¸¬ä¸¦ä¿®å¾©å•é¡Œå›æ‡‰"""
        try:
            self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Checking response data")
            responses = response_data.get("responses", [])
            self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Found {len(responses)} responses")
            
            if not responses:
                self.logger.info(f"ğŸ” DEGRADATION PREVENTION: No responses, returning original")
                return response_data
            
            # æª¢æ¸¬é€€åŒ–æ¨¡å¼
            has_degradation = False
            degradation_indicators = []
            
            for i, response in enumerate(responses):
                response_str = str(response)
                self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Checking response {i+1}: '{response_str[:50]}...'")
                
                # æª¢æ¸¬è‡ªæˆ‘ä»‹ç´¹æ¨¡å¼
                if any(pattern in response_str for pattern in ["æˆ‘æ˜¯Patient", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯", "æˆ‘æ˜¯ç—…æ‚£"]):
                    has_degradation = True
                    degradation_indicators.append("self_introduction")
                    self.logger.warning(f"ğŸš¨ DETECTED: Self-introduction pattern in response {i+1}")
                
                # æª¢æ¸¬é€šç”¨å›æ‡‰æ¨¡å¼èˆ‡éŒ¯èª¤æ¨¡æ¿
                if any(pattern in response_str for pattern in ["æˆ‘å¯èƒ½æ²’æœ‰å®Œå…¨ç†è§£", "èƒ½è«‹æ‚¨æ›å€‹æ–¹å¼èªªæ˜", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©å—", "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨ç„¡æ³•æ­£ç¢ºå›æ‡‰"]):
                    has_degradation = True
                    degradation_indicators.append("generic_responses")
                    self.logger.warning(f"ğŸš¨ DETECTED: Generic response pattern in response {i+1}")

            # è‹¥ç‹€æ…‹ç‚º CONFUSEDï¼Œä¹Ÿè¦–ç‚ºé€€åŒ–ä¸¦é€²è¡Œä¿®å¾©
            if response_data.get("state") == "CONFUSED":
                has_degradation = True
                if "confused_state" not in degradation_indicators:
                    degradation_indicators.append("confused_state")
            
            if has_degradation:
                self.logger.warning(f"ğŸš¨ DEGRADATION PREVENTION: æª¢æ¸¬åˆ°é€€åŒ–æ¨¡å¼ {degradation_indicators}ï¼Œå•Ÿå‹•ä¿®å¾©æ©Ÿåˆ¶")
                response_data["degradation_detected"] = True
                response_data["original_degradation"] = degradation_indicators
            else:
                self.logger.info(f"âœ… DEGRADATION PREVENTION: No degradation detected, keeping original responses")

            return response_data
            
        except Exception as e:
            self.logger.error(f"ğŸš¨ DEGRADATION PREVENTION: é€€åŒ–é˜²è­·å¤±æ•—: {e}")
            import traceback
            self.logger.error(f"ğŸš¨ DEGRADATION PREVENTION: Traceback: {traceback.format_exc()}")
            return response_data
    
    def _trigger_context_reset(self):
        """è§¸ç™¼ä¸Šä¸‹æ–‡é‡ç½®ï¼Œé˜²æ­¢å¾ŒçºŒé€€åŒ–"""
        try:
            # æ¸…ç†å°è©±æ­·å²ï¼Œä¿ç•™æœ€è¿‘çš„é—œéµä¿¡æ¯
            if len(self.conversation_history) > 4:
                # åªä¿ç•™æœ€è¿‘2è¼ªå°è©±
                recent_history = self.conversation_history[-4:]
                self.conversation_history = recent_history
                self.logger.info(f"ğŸ”„ åŸ·è¡Œä¸Šä¸‹æ–‡é‡ç½®ï¼Œä¿ç•™æœ€è¿‘ {len(recent_history)} æ¢è¨˜éŒ„")
            
            # é‡ç½® DSPy æ¨¡çµ„å…§éƒ¨ç‹€æ…‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            if hasattr(self.dialogue_module, 'reset_context'):
                self.dialogue_module.reset_context()
                
        except Exception as e:
            self.logger.error(f"ä¸Šä¸‹æ–‡é‡ç½®å¤±æ•—: {e}")


    def _normalize_responses(self, responses) -> list:
        if isinstance(responses, str):
            return [responses.strip()] if responses.strip() else []
        if isinstance(responses, list):
            return [str(item).strip() for item in responses if str(item).strip()]
        if responses is None:
            return []
        return [str(responses).strip()]

    def _normalize_state_value(self, raw_state: Any) -> str:
        allowed = {'NORMAL', 'CONFUSED', 'TRANSITIONING', 'TERMINATED'}

        if isinstance(raw_state, dict):
            return self._normalize_state_value(raw_state.get('state') or raw_state.get('name'))
        if isinstance(raw_state, (list, tuple)):
            for item in raw_state:
                normalized = self._normalize_state_value(item)
                if normalized:
                    return normalized
            return 'NORMAL'
        if raw_state is None:
            return 'NORMAL'

        candidate = str(raw_state).strip().upper()
        if candidate in allowed:
            return candidate
        return 'NORMAL'

    def _normalize_text_field(self, value: Any) -> str:
        if isinstance(value, dict):
            for key in ('dialogue_context', 'value', 'text', 'description'):
                if key in value:
                    return self._normalize_text_field(value[key])
            return json.dumps(value, ensure_ascii=False)
        if isinstance(value, (list, tuple)):
            return " | ".join(self._normalize_text_field(v) for v in value if v)
        return str(value).strip() if value is not None else ''

    def _normalize_context_value(self, value: Any) -> Optional[str]:
        if isinstance(value, dict):
            for key in ('context_classification', 'label', 'id', 'name', 'value'):
                if key in value:
                    return self._normalize_context_value(value[key])
            return None
        if isinstance(value, (list, tuple)):
            for item in value:
                normalized = self._normalize_context_value(item)
                if normalized:
                    return normalized
            return None
        if isinstance(value, str):
            stripped = value.strip()
            if not stripped:
                return None
            if stripped.startswith('{') and stripped.endswith('}'):
                try:
                    parsed = json.loads(stripped)
                    return self._normalize_context_value(parsed)
                except Exception:
                    return None
            return stripped
        return None

    def _filter_chinese_responses(self, responses: List[str]) -> List[str]:
        chinese_regex = re.compile(r"[\u4e00-\u9fff]")
        filtered: List[str] = [r for r in responses if chinese_regex.search(r)]
        if filtered:
            if len(filtered) < len(responses):
                self.logger.info(
                    "âš ï¸ Removed non-Chinese responses: %s",
                    [r for r in responses if r not in filtered],
                )
            return filtered[:5]
        return responses

    def _enforce_response_constraints(self, responses: List[str]) -> List[str]:
        sanitized: List[str] = []
        for response in responses:
            candidate = response.strip()
            if not candidate:
                continue
            if '?' in candidate or 'ï¼Ÿ' in candidate:
                self.logger.info(f"âš ï¸ Removed question response: {candidate}")
                continue
            if 'ä¸€èµ·ä½é™¢' in candidate or 'è·Ÿå®¶äºº' in candidate or 'è·Ÿçˆ¶æ¯' in candidate or 'è·Ÿä¸ˆå¤«' in candidate or 'è·Ÿæœ‹å‹' in candidate or 'è·Ÿå…„å¼Ÿå§å¦¹' in candidate:
                replacement = "æˆ‘ä¸€å€‹äººä½é™¢ï¼Œç›®å‰ç”±è­·ç†åœ˜éšŠç…§è­·ã€‚"
                if replacement not in sanitized:
                    sanitized.append(replacement)
                self.logger.info(f"âš ï¸ Replaced companion statement: {candidate} -> {replacement}")
                continue
            sanitized.append(candidate)

        if not sanitized:
            sanitized = ["æˆ‘åœ¨é†«é™¢æ¥å—æ²»ç™‚ï¼Œæœƒä¾ç…§é†«è­·æŒ‡ç¤ºé…åˆã€‚"]

        return sanitized[:5]

    def _attempt_sensitive_rewrite(self, original_question: str, base_prediction=None):
        """Ask Gemini to rewrite the question and fetch a new response."""
        try:
            if not self.enable_sensitive_rewrite:
                return None

            if not hasattr(self, 'sensitive_question_module'):
                return None

            conversation_summary = "\n".join(self.conversation_history[-6:])
            rewrite_prediction = self.sensitive_question_module.rewrite(
                original_question=original_question,
                conversation_summary=conversation_summary,
                character_name=self.character.name,
                character_persona=self.character.persona,
            )

            if not rewrite_prediction:
                self.logger.warning("Sensitive rewrite module returned None")
                return None

            sensitivity_flag = str(getattr(rewrite_prediction, 'sensitivity_flag', '')).strip()
            rewritten_question = str(getattr(rewrite_prediction, 'rewritten_question', '')).strip()
            reason = str(getattr(rewrite_prediction, 'sensitivity_reason', '')).strip()
            reassurance = str(getattr(rewrite_prediction, 'reassurance_message', '')).strip()

            normalized_flag = sensitivity_flag.upper()
            should_use_rewrite = normalized_flag in {'YES', 'TRUE', 'SENSITIVE'} and rewritten_question

            if not should_use_rewrite:
                self.logger.warning(
                    "Sensitive rewrite probe completed but flag=%s (reason=%s); skipping fallback.",
                    sensitivity_flag or 'UNKNOWN',
                    reason or 'æœªæä¾›',
                )
                return None

            self.logger.warning(
                "Gemini policy refusal detected. Reason: %s", reason or 'æœªæä¾›'
            )
            self.logger.warning(
                "Original question: %s | Rewritten as: %s",
                original_question,
                rewritten_question,
            )

            # Replace the last caregiver entry with the rewritten question for context continuity
            if self.conversation_history and self.conversation_history[-1].startswith("è­·ç†äººå“¡: "):
                self.conversation_history[-1] = f"è­·ç†äººå“¡(é‡è¿°): {rewritten_question}"
            else:
                self.conversation_history.append(f"è­·ç†äººå“¡(é‡è¿°): {rewritten_question}")

            rewritten_prediction = self.dialogue_module(
                user_input=rewritten_question,
                character_name=self.character.name,
                character_persona=self.character.persona,
                character_backstory=self.character.backstory,
                character_goal=self.character.goal,
                character_details=self._get_character_details(),
                conversation_history=self._format_conversation_history()
            )

            response_data = self._process_optimized_prediction(rewritten_prediction)
            response_data["sensitive_rewrite_pending"] = True
            response_data = self._apply_degradation_prevention(response_data, rewritten_question)
            response_data.pop("sensitive_rewrite_pending", None)
            response_data["sensitive_rewrite_applied"] = True
            response_data["sensitive_rewrite"] = {
                "original_question": original_question,
                "rewritten_question": rewritten_question,
                "reason": reason,
                "reassurance": reassurance,
            }

            explanation = reason or "åŸå§‹æå•å¯èƒ½è§¸åŠæ•æ„Ÿæ”¿ç­–"
            notice = f"æé†’ï¼š{explanation}ã€‚å·²æ”¹å¯«ç‚ºã€Œ{rewritten_question}ã€ã€‚"
            if reassurance:
                notice = f"{notice} {reassurance}"

            rewritten_responses = response_data.get("responses", [])
            enriched = [notice] + rewritten_responses
            response_data["responses"] = enriched[:5]
            return response_data

        except Exception as exc:  # pragma: no cover - defensive logging
            self.logger.error(f"Sensitive rewrite flow failed: {exc}", exc_info=True)
            return None
    
    def _track_session_state_changes(self, user_input: str, response_data: dict, round_number: int):
        """è¿½è¹¤æœƒè©±ç‹€æ…‹è®ŠåŒ–å’Œé€€åŒ–æŒ‡æ¨™
        
        Args:
            user_input: ç”¨æˆ¶è¼¸å…¥
            response_data: å›æ‡‰è³‡æ–™
            round_number: å°è©±è¼ªæ¬¡
        """
        try:
            self.logger.info(f"=== SESSION STATE TRACKING - Round {round_number} ===")
            
            # åŸºæœ¬æœƒè©±è³‡è¨Š
            self.logger.info(f"ğŸ”¢ CONVERSATION METRICS:")
            self.logger.info(f"  ğŸ“Š Round Number: {round_number}")
            self.logger.info(f"  ğŸ“ˆ Total Conversation History: {len(self.conversation_history)} entries")
            self.logger.info(f"  ğŸ“ Current Input Length: {len(user_input)} chars")
            
            # æœƒè©±ç‹€æ…‹åˆ†æ
            session_state = self._analyze_session_state(response_data, round_number)
            self.logger.info(f"  ğŸ­ Session State Analysis:")
            for key, value in session_state.items():
                self.logger.info(f"    {key}: {value}")
            
            # è§’è‰²ä¸€è‡´æ€§è¿½è¹¤
            consistency_score = self._calculate_consistency_score(response_data)
            self.logger.info(f"  ğŸ¯ Character Consistency Score: {consistency_score:.3f}")
            
            # å›æ‡‰å“è³ªæŒ‡æ¨™
            quality_metrics = self._calculate_response_quality_metrics(response_data)
            self.logger.info(f"  ğŸ† Response Quality Metrics:")
            for metric, value in quality_metrics.items():
                self.logger.info(f"    {metric}: {value}")
            
            # é€€åŒ–é¢¨éšªè©•ä¼°
            degradation_risk = self._assess_degradation_risk(response_data, round_number)
            self.logger.info(f"  âš ï¸  Degradation Risk: {degradation_risk['risk_level']} ({degradation_risk['score']:.2f})")
            
            # æœƒè©±è¤‡é›œåº¦åˆ†æ
            complexity_analysis = self._analyze_conversation_complexity()
            self.logger.info(f"  ğŸ§® Conversation Complexity:")
            for key, value in complexity_analysis.items():
                self.logger.info(f"    {key}: {value}")
            
            # è¨˜æ†¶ä½¿ç”¨æƒ…æ³
            memory_info = self._track_memory_usage()
            self.logger.info(f"  ğŸ’¾ Memory Usage: {memory_info}")
            
            # å¦‚æœæ˜¯é—œéµè¼ªæ¬¡ï¼ˆ3-5è¼ªï¼‰ï¼Œé¡å¤–è¨˜éŒ„
            if 3 <= round_number <= 5:
                self.logger.warning(f"ğŸš¨ CRITICAL ROUND {round_number} - Enhanced monitoring active")
                self._log_critical_round_analysis(user_input, response_data, round_number)
            
            # å„²å­˜ç‹€æ…‹æ­·å²ï¼ˆç”¨æ–¼è¶¨å‹¢åˆ†æï¼‰
            self._store_session_state_history(session_state, round_number)
            
        except Exception as e:
            self.logger.error(f"æœƒè©±ç‹€æ…‹è¿½è¹¤å¤±æ•—: {e}")
    
    def _analyze_session_state(self, response_data: dict, round_number: int) -> dict:
        """åˆ†æç•¶å‰æœƒè©±ç‹€æ…‹"""
        try:
            responses = response_data.get("responses", [])
            state = response_data.get("state", "UNKNOWN")
            context = response_data.get("dialogue_context", "UNKNOWN")
            
            return {
                "Response_Count": len(responses),
                "Dialogue_State": state,
                "Dialogue_Context": context,
                "Round_Number": round_number,
                "Original_Degradation": response_data.get("original_degradation", []),
                "Emergency_Recovery": response_data.get("emergency_recovery", False)
            }
        except Exception as e:
            return {"Error": str(e)}
    
    def _calculate_consistency_score(self, response_data: dict) -> float:
        """è¨ˆç®—è§’è‰²ä¸€è‡´æ€§åˆ†æ•¸"""
        try:
            responses = response_data.get("responses", [])
            if not responses:
                return 0.0
            
            score = 1.0
            
            # æª¢æŸ¥è‡ªæˆ‘ä»‹ç´¹æ¨¡å¼ï¼ˆåš´é‡æ‰£åˆ†ï¼‰
            for response in responses:
                if any(pattern in str(response) for pattern in ["æˆ‘æ˜¯Patient", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯"]):
                    score -= 0.4
                    break
            
            # æª¢æŸ¥é€šç”¨å›æ‡‰ï¼ˆä¸­åº¦æ‰£åˆ†ï¼‰
            for response in responses:
                if any(pattern in str(response) for pattern in ["æ²’æœ‰å®Œå…¨ç†è§£", "æ›å€‹æ–¹å¼èªªæ˜", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©"]):
                    score -= 0.2
                    break
            
            # æª¢æŸ¥é†«ç™‚ç›¸é—œæ€§ï¼ˆåŠ åˆ†ï¼‰
            medical_terms = ["ç—‡ç‹€", "æª¢æŸ¥", "å‚·å£", "æ¢å¾©", "æ²»ç™‚", "è—¥ç‰©", "è­·ç†"]
            has_medical_context = any(
                any(term in str(response) for term in medical_terms)
                for response in responses
            )
            if has_medical_context:
                score += 0.1
            
            return max(0.0, min(1.0, score))
            
        except Exception:
            return 0.5
    
    def _calculate_response_quality_metrics(self, response_data: dict) -> dict:
        """è¨ˆç®—å›æ‡‰å“è³ªæŒ‡æ¨™"""
        try:
            responses = response_data.get("responses", [])
            
            metrics = {
                "Response_Count": len(responses),
                "Average_Length": sum(len(str(r)) for r in responses) // max(1, len(responses)),
                "Has_Medical_Terms": self._has_medical_terms(responses),
                "Has_Self_Introduction": self._has_self_introduction(response_data),
                "Context_Relevance": self._calculate_context_relevance("", response_data),  # ç°¡åŒ–ç‰ˆ
                "Diversity_Score": self._calculate_response_diversity(responses)
            }
            
            return metrics
            
        except Exception as e:
            return {"Error": str(e)}
    
    def _has_medical_terms(self, responses: list) -> bool:
        """æª¢æŸ¥æ˜¯å¦åŒ…å«é†«ç™‚è¡“èª"""
        medical_terms = ["ç—‡ç‹€", "æª¢æŸ¥", "å‚·å£", "æ¢å¾©", "æ²»ç™‚", "è—¥ç‰©", "è­·ç†", "é†«å¸«", "ç—…æˆ¿"]
        return any(
            any(term in str(response) for term in medical_terms)
            for response in responses
        )
    
    def _calculate_response_diversity(self, responses: list) -> float:
        """è¨ˆç®—å›æ‡‰å¤šæ¨£æ€§åˆ†æ•¸"""
        try:
            if len(responses) <= 1:
                return 0.0
            
            # ç°¡å–®çš„å¤šæ¨£æ€§æª¢æŸ¥ï¼šè¨ˆç®—ä¸åŒé–‹é ­çš„æ¯”ä¾‹
            first_chars = [str(r)[0] if str(r) else '' for r in responses]
            unique_starts = len(set(first_chars))
            
            return unique_starts / len(responses)
            
        except Exception:
            return 0.5
    
    def _assess_degradation_risk(self, response_data: dict, round_number: int) -> dict:
        """è©•ä¼°é€€åŒ–é¢¨éšª"""
        try:
            risk_score = 0.0
            risk_factors = []
            
            # è¼ªæ¬¡é¢¨éšªï¼ˆç¬¬4-5è¼ªé¢¨éšªè¼ƒé«˜ï¼‰
            if 4 <= round_number <= 5:
                risk_score += 0.3
                risk_factors.append("Critical_Round")
            
            # å›æ‡‰å“è³ªé¢¨éšª
            responses = response_data.get("responses", [])
            if len(responses) < 3:
                risk_score += 0.2
                risk_factors.append("Few_Responses")
            
            # è‡ªæˆ‘ä»‹ç´¹é¢¨éšª
            if self._has_self_introduction(response_data):
                risk_score += 0.4
                risk_factors.append("Self_Introduction")
            
            # ç‹€æ…‹é¢¨éšª
            if response_data.get("state") == "CONFUSED":
                risk_score += 0.1
                risk_factors.append("Confused_State")
            
            # ç¢ºå®šé¢¨éšªç­‰ç´š
            if risk_score >= 0.7:
                risk_level = "HIGH"
            elif risk_score >= 0.4:
                risk_level = "MEDIUM"
            elif risk_score >= 0.2:
                risk_level = "LOW"
            else:
                risk_level = "MINIMAL"
            
            return {
                "score": risk_score,
                "risk_level": risk_level,
                "factors": risk_factors
            }
            
        except Exception as e:
            return {"score": 1.0, "risk_level": "ERROR", "factors": [str(e)]}
    
    def _analyze_conversation_complexity(self) -> dict:
        """åˆ†æå°è©±è¤‡é›œåº¦"""
        try:
            history_length = len(self.conversation_history)
            total_chars = sum(len(entry) for entry in self.conversation_history)
            
            return {
                "History_Entries": history_length,
                "Total_Characters": total_chars,
                "Average_Entry_Length": total_chars // max(1, history_length),
                "Estimated_Rounds": history_length // 2,
                "Complexity_Level": (
                    "High" if total_chars > 2000 else
                    "Medium" if total_chars > 1000 else
                    "Low"
                )
            }
        except Exception:
            return {"Error": "Analysis failed"}
    
    def _track_memory_usage(self) -> str:
        """è¿½è¹¤è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
        try:
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            return f"{memory_mb:.1f} MB"
        except ImportError:
            return "N/A (psutil not available)"
        except Exception:
            return "Error"
    
    def _log_critical_round_analysis(self, user_input: str, response_data: dict, round_number: int):
        """è¨˜éŒ„é—œéµè¼ªæ¬¡çš„è©³ç´°åˆ†æ"""
        self.logger.warning(f"ğŸ” CRITICAL ROUND {round_number} DETAILED ANALYSIS:")
        self.logger.warning(f"  ğŸ“¥ Input: '{user_input}'")
        self.logger.warning(f"  ğŸ“Š Response State: {response_data.get('state', 'UNKNOWN')}")
        self.logger.warning(f"  ğŸŒ Context: {response_data.get('dialogue_context', 'UNKNOWN')}")
        self.logger.warning(f"  ğŸ’¬ Response Count: {len(response_data.get('responses', []))}")
        
        # è©³ç´°å›æ‡‰åˆ†æ
        responses = response_data.get('responses', [])
        for i, response in enumerate(responses, 1):
            has_issues = any(pattern in str(response) for pattern in ["æˆ‘æ˜¯Patient", "æ²’æœ‰å®Œå…¨ç†è§£", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©"])
            status = "ğŸ”´ PROBLEMATIC" if has_issues else "âœ… OK"
            self.logger.warning(f"    Response {i}: {status} - '{str(response)[:100]}...'")
    
    def _store_session_state_history(self, session_state: dict, round_number: int):
        """å„²å­˜æœƒè©±ç‹€æ…‹æ­·å²"""
        try:
            if not hasattr(self, '_session_history'):
                self._session_history = []
            
            history_entry = {
                "round": round_number,
                "timestamp": time.time(),
                "state": session_state
            }
            
            self._session_history.append(history_entry)
            
            # åªä¿ç•™æœ€è¿‘10è¼ªçš„è¨˜éŒ„
            if len(self._session_history) > 10:
                self._session_history = self._session_history[-10:]
                
        except Exception as e:
            self.logger.error(f"ç‹€æ…‹æ­·å²å„²å­˜å¤±æ•—: {e}")
    
    def _generate_emergency_response(self, user_input: str) -> str:
        """ç”Ÿæˆç·Šæ€¥æ¢å¾©å›æ‡‰ï¼Œç•¶æ‰€æœ‰å…¶ä»–æ–¹æ³•éƒ½å¤±æ•—æ™‚ä½¿ç”¨"""
        self.logger.warning(f"ğŸš¨ ç”Ÿæˆç·Šæ€¥æ¢å¾©å›æ‡‰ for: {user_input}")
        emergency_responses = [
            "EmergencyFallback: dialogue manager failed to recover; please review server logs."
        ]

        emergency_data = {
            "status": "success",
            "responses": emergency_responses,
            "state": "NORMAL", 
            "dialogue_context": "ç·Šæ€¥æ¢å¾©æ¨¡å¼",
            "session_id": getattr(self, 'current_session_id', None),
            "emergency_recovery": True,
            "speech_recognition_options": None,
            "original_transcription": None
        }
        
        return json.dumps(emergency_data, ensure_ascii=False)

    def cleanup(self):
        """æ¸…ç†è³‡æº"""
        self.logger.info("æ¸…ç†å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨")
        
        # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
        final_stats = self.get_optimization_statistics()
        self.logger.info(f"æœ€çµ‚å„ªåŒ–çµ±è¨ˆ: {final_stats}")
        
        if hasattr(self, 'dialogue_module') and hasattr(self.dialogue_module, 'cleanup'):
            self.dialogue_module.cleanup()


# æ¸¬è©¦å‡½æ•¸
def test_optimized_dialogue_manager():
    """æ¸¬è©¦å„ªåŒ–ç‰ˆå°è©±ç®¡ç†å™¨"""
    print("ğŸ§ª æ¸¬è©¦å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨...")
    
    try:
        # å‰µå»ºæ¸¬è©¦è§’è‰²
        from ..character import Character
        test_character = Character(
            name="æ¸¬è©¦ç—…æ‚£",
            persona="å‹å–„ä½†æ“”å¿ƒçš„ç—…æ‚£",
            backstory="ä½é™¢ä¸­é€²è¡Œåº·å¾©æ²»ç™‚",
            goal="ç›¡å¿«åº·å¾©å‡ºé™¢"
        )
        
        # å‰µå»ºå„ªåŒ–ç‰ˆç®¡ç†å™¨
        manager = OptimizedDialogueManagerDSPy(test_character)
        
        print("âœ… å„ªåŒ–ç‰ˆå°è©±ç®¡ç†å™¨å‰µå»ºæˆåŠŸ")
        print(manager._get_optimization_summary())
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_optimized_dialogue_manager()

#!/usr/bin/env python3
"""
å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨

ä½¿ç”¨çµ±ä¸€å°è©±æ¨¡çµ„ï¼Œå°‡ API èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ï¼Œ
è§£æ±º Gemini API é…é¡é™åˆ¶å•é¡Œã€‚
"""

import json
import logging
from typing import Optional, Union

from ..dialogue import DialogueManager
from ..character import Character
from .unified_dialogue_module import UnifiedDSPyDialogueModule

logger = logging.getLogger(__name__)


class OptimizedDialogueManagerDSPy(DialogueManager):
    """å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨
    
    ä¸»è¦å„ªåŒ–ï¼š
    - API èª¿ç”¨å¾ 3æ¬¡ æ¸›å°‘åˆ° 1æ¬¡ (ç¯€çœ 66.7% é…é¡ä½¿ç”¨)
    - ä¿æŒå®Œå…¨çš„ API å…¼å®¹æ€§
    - æä¾›è©³ç´°çš„ç¯€çœçµ±è¨ˆ
    """
    
    def __init__(self, character: Character, use_terminal: bool = False, log_dir: str = "logs"):
        """åˆå§‹åŒ–å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨
        
        Args:
            character: Character instance containing the NPC's information (as patient identifier)
            use_terminal: Whether to use terminal mode for interaction
            log_dir: Directory to save interaction logs
        """
        # åˆå§‹åŒ–çˆ¶é¡
        super().__init__(character, use_terminal, log_dir)
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("OptimizedDialogueManagerDSPy.__init__ - ä½¿ç”¨çµ±ä¸€å°è©±æ¨¡çµ„")
        
        # åˆå§‹åŒ–å„ªåŒ–çš„ DSPy çµ„ä»¶
        try:
            self.dialogue_module = UnifiedDSPyDialogueModule()
            self.optimization_enabled = True
            self.logger.info("å„ªåŒ–çµ±ä¸€å°è©±æ¨¡çµ„åˆå§‹åŒ–æˆåŠŸ - API èª¿ç”¨ç¯€çœ 66.7%")
        except Exception as e:
            self.logger.error(f"çµ±ä¸€å°è©±æ¨¡çµ„åˆå§‹åŒ–å¤±æ•—: {e}")
            self.optimization_enabled = False
            # å›é€€åˆ°åŸå§‹å¯¦ç¾
            from .dialogue_manager_dspy import DialogueManagerDSPy
            fallback_manager = DialogueManagerDSPy(character, use_terminal, log_dir)
            self.dialogue_module = fallback_manager.dialogue_module
            self.logger.warning("å·²å›é€€åˆ°åŸå§‹ DSPy å¯¦ç¾")
        
        # çµ±è¨ˆè¿½è¹¤
        self.optimization_stats = {
            'total_conversations': 0,
            'api_calls_saved': 0,
            'estimated_quota_saved_percent': 0.0
        }
    
    async def process_turn(self, user_input: str, gui_selected_response: Optional[str] = None) -> Union[str, dict]:
        """è™•ç†å„ªåŒ–ç‰ˆå°è©±è¼ªæ¬¡
        
        Args:
            user_input: The user's input text
            gui_selected_response: Selected response in GUI mode (optional)
            
        Returns:
            Either a string response (terminal mode) or JSON response (GUI mode)
        """
        if not self.optimization_enabled:
            # å›é€€åˆ°çˆ¶é¡å¯¦ç¾
            return await super().process_turn(user_input, gui_selected_response)
        
        self.optimization_stats['total_conversations'] += 1
        
        try:
            self.logger.info(f"=== å„ªåŒ–ç‰ˆå°è©±è™•ç† (ç¬¬ {self.optimization_stats['total_conversations']} æ¬¡) ===")
            self.logger.info(f"ç”¨æˆ¶è¼¸å…¥: {user_input}")
            
            # æª¢æŸ¥é‡è¤‡è¼¸å…¥ - é¿å…åœ¨æœƒè©±ä¸­æ·»åŠ ç›¸åŒçš„è¼¸å…¥
            last_user_input = None
            if self.conversation_history:
                for entry in reversed(self.conversation_history):
                    if entry.startswith("è­·ç†äººå“¡: "):
                        last_user_input = entry[5:]  # ç§»é™¤ "è­·ç†äººå“¡: " å‰ç¶´
                        break
            
            is_duplicate_input = (last_user_input == user_input)
            
            # åªæœ‰ä¸æ˜¯é‡è¤‡è¼¸å…¥æ™‚æ‰è¨˜éŒ„åˆ°å°è©±æ­·å²
            if not is_duplicate_input:
                self.conversation_history.append(f"è­·ç†äººå“¡: {user_input}")
                self.logger.info(f"âœ… æ–°è¼¸å…¥å·²è¨˜éŒ„åˆ°å°è©±æ­·å²")
            else:
                self.logger.info(f"âš ï¸ æª¢æ¸¬åˆ°é‡è¤‡è¼¸å…¥ï¼Œè·³éè¨˜éŒ„åˆ°å°è©±æ­·å²ï¼Œé¿å…æ··äº‚")
            
            # ä½¿ç”¨å„ªåŒ–çš„çµ±ä¸€å°è©±æ¨¡çµ„ (åƒ…1æ¬¡ API èª¿ç”¨)
            prediction = self.dialogue_module(
                user_input=user_input,
                character_name=self.character.name,
                character_persona=self.character.persona,
                character_backstory=self.character.backstory,
                character_goal=self.character.goal,
                character_details=self._get_character_details(),
                conversation_history=self._format_conversation_history()
            )
            
            self.logger.info(f"å„ªåŒ–è™•ç†å®Œæˆ:")
            self.logger.info(f"  - API èª¿ç”¨æ¬¡æ•¸: 1 (åŸæœ¬éœ€è¦ 3æ¬¡)")
            self.logger.info(f"  - ç¯€çœé…é¡ä½¿ç”¨: 66.7%")
            self.logger.info(f"  - å›æ‡‰æ•¸é‡: {len(prediction.responses)}")
            self.logger.info(f"  - æƒ…å¢ƒåˆ†é¡: {prediction.context_classification}")
            
            # æ›´æ–°ç¯€çœçµ±è¨ˆ
            saved_calls = prediction.processing_info.get('api_calls_saved', 2)
            self.optimization_stats['api_calls_saved'] += saved_calls
            self.optimization_stats['estimated_quota_saved_percent'] = (
                (self.optimization_stats['api_calls_saved'] / 
                 (self.optimization_stats['total_conversations'] * 3)) * 100
                if self.optimization_stats['total_conversations'] > 0 else 0
            )
            
            # è™•ç†å›æ‡‰çµæœ
            response_data = self._process_optimized_prediction(prediction)
            
            # é—œéµä¿®å¾©ï¼šæª¢æŸ¥ä¸¦ä¿®å¾©é€€åŒ–å›æ‡‰
            response_data = self._apply_degradation_prevention(response_data, user_input)
            
            # æ›´æ–°å°è©±ç‹€æ…‹
            self._update_dialogue_state(response_data)
            
            # è™•ç†çµ‚ç«¯æ©Ÿæ¨¡å¼æˆ– GUI æ¨¡å¼
            if self.use_terminal:
                return self._handle_terminal_mode(user_input, response_data)
            else:
                return self._handle_gui_mode(user_input, response_data, gui_selected_response)
                
        except Exception as e:
            self.logger.error(f"å„ªåŒ–ç‰ˆå°è©±è™•ç†å¤±æ•—: {e}")
            
            # å˜—è©¦å¾çˆ¶é¡ç²å–å›æ‡‰ï¼Œç„¶å¾Œæ‡‰ç”¨é€€åŒ–é˜²è­·
            try:
                fallback_result = await super().process_turn(user_input, gui_selected_response)
                
                # å¦‚æœçˆ¶é¡è¿”å› JSON å­—ä¸²ï¼Œè§£æå®ƒ
                if isinstance(fallback_result, str):
                    try:
                        fallback_data = json.loads(fallback_result)
                        # æ‡‰ç”¨é€€åŒ–é˜²è­·åˆ°çˆ¶é¡å›æ‡‰
                        protected_data = self._apply_degradation_prevention(fallback_data, user_input)
                        return json.dumps(protected_data, ensure_ascii=False)
                    except json.JSONDecodeError:
                        # ä¸æ˜¯ JSONï¼Œç›´æ¥è¿”å›
                        return fallback_result
                else:
                    # çˆ¶é¡è¿”å›å­—å…¸ï¼Œç›´æ¥æ‡‰ç”¨é˜²è­·
                    return self._apply_degradation_prevention(fallback_result, user_input)
                    
            except Exception as fallback_error:
                self.logger.error(f"çˆ¶é¡å›é€€ä¹Ÿå¤±æ•—: {fallback_error}")
                # æœ€çµ‚é˜²è­·ï¼šç”Ÿæˆå®‰å…¨çš„æ¢å¾©å›æ‡‰
                return self._generate_emergency_response(user_input)
    
    def _get_character_details(self) -> str:
        """ç²å–è§’è‰²è©³ç´°è³‡è¨Šçš„å­—ä¸²è¡¨ç¤º"""
        details = {}
        
        # å¾è§’è‰²å°è±¡ç²å–è¨­å®š
        if hasattr(self.character, 'fixed_settings'):
            details.update(self.character.fixed_settings)
        if hasattr(self.character, 'floating_settings'):
            details.update(self.character.floating_settings)
        
        # æ·»åŠ å…¶ä»–å±¬æ€§
        for attr in ['age', 'gender', 'medical_condition']:
            if hasattr(self.character, attr):
                details[attr] = getattr(self.character, attr)
        
        return json.dumps(details, ensure_ascii=False) if details else "{}"
    
    def _process_optimized_prediction(self, prediction) -> dict:
        """è™•ç†å„ªåŒ–ç‰ˆé æ¸¬çµæœ"""
        try:
            responses = getattr(prediction, 'responses', [])
            state = getattr(prediction, 'state', 'NORMAL')
            dialogue_context = getattr(prediction, 'dialogue_context', 'ä¸€èˆ¬å°è©±')
            context_classification = getattr(prediction, 'context_classification', 'daily_routine_examples')
            
            # ç¢ºä¿å›æ‡‰æ ¼å¼æ­£ç¢º
            if isinstance(responses, str):
                try:
                    responses = json.loads(responses)
                except json.JSONDecodeError:
                    responses = [responses]
            
            if not isinstance(responses, list):
                responses = [str(responses)]
            
            if not responses:
                responses = ["æˆ‘éœ€è¦ä¸€é»æ™‚é–“æ€è€ƒ..."]
            
            return {
                "responses": responses,
                "state": state,
                "dialogue_context": dialogue_context,
                "context_classification": context_classification,
                "optimization_info": {
                    "api_calls_used": 1,
                    "api_calls_saved": 2,
                    "efficiency_improvement": "66.7%"
                }
            }
            
        except Exception as e:
            self.logger.error(f"å„ªåŒ–é æ¸¬çµæœè™•ç†å¤±æ•—: {e}")
            return {
                "responses": ["æŠ±æ­‰ï¼Œè™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤"],
                "state": "CONFUSED",
                "dialogue_context": "ç³»çµ±éŒ¯èª¤"
            }
    
    def _update_dialogue_state(self, response_data: dict):
        """æ›´æ–°å°è©±ç‹€æ…‹"""
        try:
            from ..state import DialogueState
            new_state = response_data.get("state", "NORMAL")
            self.current_state = DialogueState(new_state)
            
            dialogue_context = response_data.get("dialogue_context", "")
            if dialogue_context:
                print(f"å„ªåŒ– DSPy åˆ¤æ–·çš„å°è©±æƒ…å¢ƒ: {dialogue_context}")
                
        except ValueError as e:
            self.logger.warning(f"ç„¡æ•ˆç‹€æ…‹ï¼Œè¨­ç½®ç‚º CONFUSED: {e}")
            from ..state import DialogueState
            self.current_state = DialogueState.CONFUSED
    
    def _handle_terminal_mode(self, user_input: str, response_data: dict) -> str:
        """è™•ç†çµ‚ç«¯æ©Ÿæ¨¡å¼çš„äº’å‹•"""
        import keyboard
        
        responses = response_data["responses"]
        
        print(f"\n{self.character.name} çš„å›æ‡‰é¸é …ï¼ˆå„ªåŒ– DSPy ç”Ÿæˆï¼Œç¯€çœ 66.7% API èª¿ç”¨ï¼‰ï¼š")
        for i, response in enumerate(responses, 1):
            print(f"{i}. {response}")
        print("0. é€™äº›é¸é …éƒ½ä¸é©åˆï¼ˆè·³éï¼Œç›´æ¥é€²å…¥ä¸‹ä¸€è¼ªå°è©±ï¼‰")
        print("q. çµæŸå°è©±")
        print("s. é¡¯ç¤ºå„ªåŒ–çµ±è¨ˆ")
        print("\nè«‹æŒ‰æ•¸å­—éµ 0-5 é¸æ“‡é¸é …ï¼Œs æŸ¥çœ‹çµ±è¨ˆï¼Œæˆ–æŒ‰ q çµæŸå°è©±...")
        
        while True:
            event = keyboard.read_event(suppress=True)
            if event.event_type == 'down':
                if event.name == '0':
                    print("\nè·³éæ­¤è¼ªå›æ‡‰ï¼Œè«‹ç¹¼çºŒå°è©±")
                    self.conversation_history.append("(è·³éæ­¤è¼ªå›æ‡‰)")
                    self.log_interaction(user_input, responses, selected_response="(è·³éæ­¤è¼ªå›æ‡‰)")
                    self.save_interaction_log()
                    return ""
                elif event.name == 'q':
                    print("\nçµæŸå°è©±")
                    print(self._get_optimization_summary())
                    self.save_interaction_log()
                    return "quit"
                elif event.name == 's':
                    print("\n" + self._get_optimization_summary())
                    continue
                elif event.name in ['1', '2', '3', '4', '5']:
                    choice = int(event.name)
                    if choice <= len(responses):
                        selected_response = responses[choice - 1]
                        print(f"\nå·²é¸æ“‡é¸é … {choice}: {selected_response}")
                        self.conversation_history.append(f"{self.character.name}: {selected_response}")
                        self.log_interaction(user_input, responses, selected_response=selected_response)
                        self.save_interaction_log()
                        return selected_response
    
    def _handle_gui_mode(self, user_input: str, response_data: dict, gui_selected_response: Optional[str] = None) -> str:
        """è™•ç† GUI æ¨¡å¼çš„äº’å‹•"""
        # è¨˜éŒ„äº’å‹•
        self.log_interaction(user_input, response_data["responses"], selected_response=gui_selected_response)
        self.save_interaction_log()
        
        # è¿”å› JSON æ ¼å¼å›æ‡‰
        return json.dumps(response_data, ensure_ascii=False)
    
    def get_optimization_statistics(self) -> dict:
        """ç²å–å„ªåŒ–çµ±è¨ˆè³‡è¨Š"""
        base_stats = {}
        if hasattr(self, 'dialogue_module') and hasattr(self.dialogue_module, 'get_unified_statistics'):
            base_stats = self.dialogue_module.get_unified_statistics()
        
        return {
            **base_stats,
            **self.optimization_stats,
            'optimization_enabled': self.optimization_enabled,
            'efficiency_summary': {
                'conversations_processed': self.optimization_stats['total_conversations'],
                'total_api_calls_saved': self.optimization_stats['api_calls_saved'],
                'quota_savings_percent': f"{self.optimization_stats['estimated_quota_saved_percent']:.1f}%",
                'calls_per_conversation': '1 (åŸæœ¬ 3æ¬¡)',
                'optimization_factor': '3x æ•ˆç‡æå‡'
            }
        }
    
    def _get_optimization_summary(self) -> str:
        """ç²å–å„ªåŒ–æ‘˜è¦å­—ä¸²"""
        stats = self.get_optimization_statistics()
        return f"""
ğŸ¯ API èª¿ç”¨å„ªåŒ–çµ±è¨ˆæ‘˜è¦:
  - è™•ç†å°è©±æ•¸é‡: {stats['conversations_processed']}
  - ç¯€çœ API èª¿ç”¨: {stats['total_api_calls_saved']} æ¬¡
  - é…é¡ç¯€çœç‡: {stats['quota_savings_percent']}
  - æ•ˆç‡æå‡: æ¯æ¬¡å°è©±å¾ 3æ¬¡èª¿ç”¨ â†’ 1æ¬¡èª¿ç”¨
  - æ•´é«”æ•ˆç‡: æå‡ 3å€ï¼Œè§£æ±ºé…é¡é™åˆ¶å•é¡Œ
"""
    
    def _apply_degradation_prevention(self, response_data: dict, user_input: str) -> dict:
        """æ‡‰ç”¨é€€åŒ–é˜²è­·æªæ–½ï¼Œæª¢æ¸¬ä¸¦ä¿®å¾©å•é¡Œå›æ‡‰"""
        try:
            self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Checking response data")
            responses = response_data.get("responses", [])
            self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Found {len(responses)} responses")
            
            if not responses:
                self.logger.info(f"ğŸ” DEGRADATION PREVENTION: No responses, returning original")
                return response_data
            
            # æª¢æ¸¬é€€åŒ–æ¨¡å¼
            has_degradation = False
            degradation_indicators = []
            
            for i, response in enumerate(responses):
                response_str = str(response)
                self.logger.info(f"ğŸ” DEGRADATION PREVENTION: Checking response {i+1}: '{response_str[:50]}...'")
                
                # æª¢æ¸¬è‡ªæˆ‘ä»‹ç´¹æ¨¡å¼
                if any(pattern in response_str for pattern in ["æˆ‘æ˜¯Patient", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯", "æˆ‘æ˜¯ç—…æ‚£"]):
                    has_degradation = True
                    degradation_indicators.append("self_introduction")
                    self.logger.warning(f"ğŸš¨ DETECTED: Self-introduction pattern in response {i+1}")
                
                # æª¢æ¸¬é€šç”¨å›æ‡‰æ¨¡å¼
                if any(pattern in response_str for pattern in ["æˆ‘å¯èƒ½æ²’æœ‰å®Œå…¨ç†è§£", "èƒ½è«‹æ‚¨æ›å€‹æ–¹å¼èªªæ˜", "æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©å—"]):
                    has_degradation = True
                    degradation_indicators.append("generic_responses")
                    self.logger.warning(f"ğŸš¨ DETECTED: Generic response pattern in response {i+1}")
            
            if has_degradation:
                self.logger.warning(f"ğŸš¨ DEGRADATION PREVENTION: æª¢æ¸¬åˆ°é€€åŒ–æ¨¡å¼ {degradation_indicators}ï¼Œå•Ÿå‹•ä¿®å¾©æ©Ÿåˆ¶")
                
                # ç”Ÿæˆä¿®å¾©å¾Œçš„å›æ‡‰
                fixed_responses = self._generate_recovery_responses(user_input)
                
                response_data["responses"] = fixed_responses
                response_data["state"] = "NORMAL"
                response_data["dialogue_context"] = "å·²ä¿®å¾©çš„é†«ç™‚å°è©±"
                response_data["recovery_applied"] = True
                response_data["original_degradation"] = degradation_indicators
                
                # è§¸ç™¼ä¸Šä¸‹æ–‡é‡ç½®ä»¥é˜²æ­¢å¾ŒçºŒé€€åŒ–
                self._trigger_context_reset()
                
                self.logger.info(f"âœ… DEGRADATION PREVENTION: é€€åŒ–ä¿®å¾©å®Œæˆï¼Œç”Ÿæˆ {len(fixed_responses)} å€‹ä¿®å¾©å›æ‡‰")
            else:
                self.logger.info(f"âœ… DEGRADATION PREVENTION: No degradation detected, keeping original responses")
            
            return response_data
            
        except Exception as e:
            self.logger.error(f"ğŸš¨ DEGRADATION PREVENTION: é€€åŒ–é˜²è­·å¤±æ•—: {e}")
            import traceback
            self.logger.error(f"ğŸš¨ DEGRADATION PREVENTION: Traceback: {traceback.format_exc()}")
            return response_data
    
    def _generate_recovery_responses(self, user_input: str) -> list:
        """ç”Ÿæˆæ¢å¾©æ€§å›æ‡‰ï¼ŒåŸºæ–¼è§’è‰²è¨­å®šå’Œè¼¸å…¥å…§å®¹"""
        # åŸºæ–¼ç”¨æˆ¶è¼¸å…¥ç”Ÿæˆé©åˆçš„ç—…æ‚£å›æ‡‰
        input_lower = user_input.lower()
        
        if "æ„Ÿè¦º" in user_input or "æ€éº¼æ¨£" in user_input:
            return [
                "é‚„å¯ä»¥ï¼Œå‚·å£æœ‰é»ç·Šç¹ƒã€‚",
                "æ¢å¾©å¾—é‚„ä¸éŒ¯ï¼Œå°±æ˜¯æœ‰é»ç´¯ã€‚",
                "é‚„è¡Œï¼Œä½†æœ‰æ™‚æœƒè¦ºå¾—ä¸å¤ªèˆ’æœã€‚",
                "ç›®å‰ç‹€æ³é‚„ç©©å®šã€‚",
                "æ„Ÿè¦ºæ¯”æ˜¨å¤©å¥½ä¸€äº›äº†ã€‚"
            ]
        elif "ç™¼ç‡’" in user_input or "ä¸èˆ’æœ" in user_input:
            return [
                "ç›®å‰æ²’æœ‰ç™¼ç‡’ï¼Œä½†å‚·å£å‘¨åœæœ‰é»è…«è„¹ã€‚",
                "æ²’æœ‰ç™¼ç‡’ï¼Œä½†å¶çˆ¾æœƒè¦ºå¾—æœ‰é»ç—›ã€‚",
                "é«”æº«æ­£å¸¸ï¼Œå°±æ˜¯æœ‰äº›ç–²å‹ã€‚",
                "æ²’æœ‰æ˜é¡¯ç™¼ç‡’ç—‡ç‹€ã€‚",
                "ç›®å‰æ²’æœ‰ç™¼ç‡’ï¼Œä½†ä¼‘æ¯ä¸å¤ªå¥½ã€‚"
            ]
        elif "ç—‡ç‹€" in user_input:
            return [
                "ä¸»è¦å°±æ˜¯å‚·å£æœ‰é»ç·Šç¹ƒæ„Ÿã€‚",
                "å¶çˆ¾æœƒè¦ºå¾—æœ‰é»ç–¼ç—›ï¼Œå…¶ä»–é‚„å¥½ã€‚",
                "å°±æ˜¯åƒæ±è¥¿æ™‚æœ‰é»å›°é›£ã€‚",
                "æ²’æœ‰å…¶ä»–ç‰¹åˆ¥ä¸èˆ’æœçš„åœ°æ–¹ã€‚",
                "é™¤äº†å‚·å£ï¼Œå…¶ä»–éƒ½é‚„æ­£å¸¸ã€‚"
            ]
        elif "æª¢æŸ¥" in user_input:
            return [
                "å¥½ï¼Œéƒ½è½ä½ å€‘çš„å®‰æ’ã€‚",
                "å¯ä»¥ï¼Œæª¢æŸ¥æ˜¯å¿…è¦çš„ã€‚",
                "æ²’å•é¡Œï¼Œä»€éº¼æ™‚å€™æª¢æŸ¥ï¼Ÿ",
                "å¥½çš„ï¼Œæˆ‘æœƒé…åˆã€‚",
                "éœ€è¦åšä»€éº¼æº–å‚™å—ï¼Ÿ"
            ]
        else:
            # é€šç”¨æ¢å¾©å›æ‡‰
            return [
                "å¥½çš„ï¼Œæˆ‘çŸ¥é“äº†ã€‚",
                "å—¯ï¼Œè½èµ·ä¾†åˆç†ã€‚",
                "æˆ‘æœƒé…åˆæ²»ç™‚çš„ã€‚",
                "è¬è¬ä½ çš„é—œå¿ƒã€‚",
                "é‚£å°±éº»ç…©ä½ å€‘äº†ã€‚"
            ]
    
    def _trigger_context_reset(self):
        """è§¸ç™¼ä¸Šä¸‹æ–‡é‡ç½®ï¼Œé˜²æ­¢å¾ŒçºŒé€€åŒ–"""
        try:
            # æ¸…ç†å°è©±æ­·å²ï¼Œä¿ç•™æœ€è¿‘çš„é—œéµä¿¡æ¯
            if len(self.conversation_history) > 4:
                # åªä¿ç•™æœ€è¿‘2è¼ªå°è©±
                recent_history = self.conversation_history[-4:]
                self.conversation_history = recent_history
                self.logger.info(f"ğŸ”„ åŸ·è¡Œä¸Šä¸‹æ–‡é‡ç½®ï¼Œä¿ç•™æœ€è¿‘ {len(recent_history)} æ¢è¨˜éŒ„")
            
            # é‡ç½® DSPy æ¨¡çµ„å…§éƒ¨ç‹€æ…‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            if hasattr(self.dialogue_module, 'reset_context'):
                self.dialogue_module.reset_context()
                
        except Exception as e:
            self.logger.error(f"ä¸Šä¸‹æ–‡é‡ç½®å¤±æ•—: {e}")
    
    def _generate_emergency_response(self, user_input: str) -> str:
        """ç”Ÿæˆç·Šæ€¥æ¢å¾©å›æ‡‰ï¼Œç•¶æ‰€æœ‰å…¶ä»–æ–¹æ³•éƒ½å¤±æ•—æ™‚ä½¿ç”¨"""
        self.logger.warning(f"ğŸš¨ ç”Ÿæˆç·Šæ€¥æ¢å¾©å›æ‡‰ for: {user_input}")
        
        # æ ¹æ“šè¼¸å…¥ç”ŸæˆåŸºæœ¬çš„ç—…æ‚£å›æ‡‰
        emergency_responses = self._generate_recovery_responses(user_input)
        
        emergency_data = {
            "status": "success",
            "responses": emergency_responses,
            "state": "NORMAL", 
            "dialogue_context": "ç·Šæ€¥æ¢å¾©æ¨¡å¼",
            "session_id": getattr(self, 'current_session_id', None),
            "emergency_recovery": True,
            "speech_recognition_options": None,
            "original_transcription": None
        }
        
        return json.dumps(emergency_data, ensure_ascii=False)

    def cleanup(self):
        """æ¸…ç†è³‡æº"""
        self.logger.info("æ¸…ç†å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨")
        
        # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
        final_stats = self.get_optimization_statistics()
        self.logger.info(f"æœ€çµ‚å„ªåŒ–çµ±è¨ˆ: {final_stats}")
        
        if hasattr(self, 'dialogue_module') and hasattr(self.dialogue_module, 'cleanup'):
            self.dialogue_module.cleanup()


# æ¸¬è©¦å‡½æ•¸
def test_optimized_dialogue_manager():
    """æ¸¬è©¦å„ªåŒ–ç‰ˆå°è©±ç®¡ç†å™¨"""
    print("ğŸ§ª æ¸¬è©¦å„ªåŒ–ç‰ˆ DSPy å°è©±ç®¡ç†å™¨...")
    
    try:
        # å‰µå»ºæ¸¬è©¦è§’è‰²
        from ..character import Character
        test_character = Character(
            name="æ¸¬è©¦ç—…æ‚£",
            persona="å‹å–„ä½†æ“”å¿ƒçš„ç—…æ‚£",
            backstory="ä½é™¢ä¸­é€²è¡Œåº·å¾©æ²»ç™‚",
            goal="ç›¡å¿«åº·å¾©å‡ºé™¢"
        )
        
        # å‰µå»ºå„ªåŒ–ç‰ˆç®¡ç†å™¨
        manager = OptimizedDialogueManagerDSPy(test_character)
        
        print("âœ… å„ªåŒ–ç‰ˆå°è©±ç®¡ç†å™¨å‰µå»ºæˆåŠŸ")
        print(manager._get_optimization_summary())
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_optimized_dialogue_manager()